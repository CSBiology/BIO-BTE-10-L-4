[{"uri":"/BIO-BTE-10-L-4/index.html","title":"BIO-BTE-10-L-4\n","content":"# BIO-BTE-10-L-4\n\n\u003Cbr\u003E\n\nDeutscher titel: **Wissenschaftliche Programmierung f\u00FCr Biolog*innen (Projektarbeit)**\n\nEnglish title: **Scientific Programming For Biologists (project work)**\n\nKIS: [BIO-BTE-10-L-4](https://www.kis.uni-kl.de/campus/all/event.asp?gguid=0xE21F6D88E774426AAF47627AB6FC59BB\u0026tguid=0xA0CC12CC38514E09833533E643742D94)\n\n**Credit Points (CP): 9**\n\n**Vorraussetzungen/Requirements:** [BIO-BTE-12-V-4](https://csbiology.github.io/BIO-BTE-12-V-4/)\n\n**Table of contents**\n\n\u003C!-- TOC --\u003E\n\n- [Kursbeschreibung(deutsch)](#kursbeschreibungdeutsch)\n    - [Ablauf](#ablauf)\n- [Course description(english)](#course-descriptionenglish)\n    - [Procedure](#procedure)\n\n\u003C!-- /TOC --\u003E\n\n## Kursbeschreibung(deutsch)\n\nSetzen Sie Ihre F\u00E4higkeiten mit einer individuellen Projektarbeit im Bereich der Bioinformatik in die Praxis um. M\u00F6gliche Projektthemen erstrecken sich \u00FCber das gesamte Spektrum der Bioinformatik von Algorithmus- bis zur Webdienstimplementierung. Besprechen sie ihre eigene Themenidee oder w\u00E4hlen Sie ein vorgeschlagenes Projekt f\u00FCr sich aus.\n\n### Ablauf\n\n- **Themenwahl**: Die angebotenen Projektarbeitsthemen k\u00F6nnen sie der Sidebar links entnehmen. Die jeweiligen Artikel geben bereits einen detailierten \u00DCberblick \u00FCber das Thema und verschiedene Hinweise und Tipps f\u00FCr deren Bearbeitung. \n\n- **Themenbearbeitung**: Nach einem Einf\u00FChrungsgespr\u00E4ch bearbeiten sie das Thema digital in Eigenregie. Die Literaturrecherche, das Suchen und Analysieren eventueller Referenzimplementationen, sowie das Implementieren ihrer L\u00F6sungen in F# sollten eigenst\u00E4ndig durchgef\u00FChrt werden. Wir stehen ihnen dabei nat\u00FCrlich bei technischen und/oder Verst\u00E4ndnisproblemen zur Verf\u00FCgung -\n\n    _[Optional]_ Um ihre Arbeit zu versionieren und leichter teilbar zu machen, empfiehlt sich die Einrichtung und Pflege eines [Repositories auf GitHub](https://guides.github.com/activities/hello-world/). Bei Interesse kann hier auch eine Einf\u00FChrung unsererseits erfolgen.\n\n- **Leistungsnachweis**: Der Leistungsnachweis erfolgt durch eine Nachbesprechung und ein Protokoll mitsamt Dokumentation und Anwendungsbeispiel des Projekts. Art und Pr\u00E4sentation des Protokolls kann abh\u00E4ngig vom Projekt leicht unterschiedlich sein, grunds\u00E4tzlich sollten Folgende Punkte aber immer beachtet werden:\n    - Einleitender Text zu Problemstellung, Themenfeld, etc. (hier gerne an der Projektvorstellung orientieren)\n    - Schritt-f\u00FCr-Schritt Erkl\u00E4rung der Implementation der Probleml\u00F6sung **mit Codebeispielen** im [_Blogpost Stil_]()\n    - Anwendungsbeispiel **mit Codebeispielen**\n\n## Course description(english)\n\nPut your skills into practice by working on an individual project work in the field of bioinformatics. Project topics span the range of bioinformatic application from algorithms to web service implementation. Discuss your own ideas as project topic or select a suggested project.\n\n### Procedure\n\ncoming soon"},{"uri":"/BIO-BTE-10-L-4/projects/PrimsAlgorithm.html","title":"Reduce complex graphs to the best paths","content":"(**\n---\ntitle: Reduce complex graphs to the best paths\ncategory: projects\ncategoryindex: 1\nindex: 4\n---\n*)\n\n(** \n# Reduce complex graphs to the best paths\n\n\u0060Imagine you\u0027re elected Minister of Infrastructure and tasked to build a road grid. This grid is supposed to connect all cities. Your budget is pretty tight though so the combined length of the roads should be as low as possible\u0060\n\n\nProblem\u0027s like this are predetermined to be regarded as a graph problem. Graphs are structures that consist of two different kinds of components:\n- Vertices are the entities of the graph\n- Edges connect these vertices\n\nAlthough simple in principal, graphs can become complex as they grow. Graph algorithms have emerged for all kinds of problems. One of them is finding minimum spanning trees which have been used to solve the problem described in the beginning.\n\n\n##### Interested?\n\nContinue reading and write a mail to [weil@bio.uni-kl.de](mailto:weil@bio.uni-kl.de) or [muehlhaus@bio.uni-kl.de](mailto:muehlhaus@bio.uni-kl.de)\n\n## Content\n\n\u003Cbr\u003E\n\n1. [Minimum spanning trees](#Minimum-spanning-trees) \n\n2. [Aim for this project](#Aim-for-this-project)\n\n3. [Prim\u0027s algorithm](#Prim-s-algorithm) \n\n4. [References](#References)\n\n5. [Coding clues](#Coding-clues)\n\n## Minimum spanning trees\n\nA minimum spanning tree (MST) or minimum weight spanning tree is a subset of the edges of a connected, edge-weighted undirected graph that connects all the vertices together, without any cycles and with the minimum possible total edge weight.\n\nAs indicated above, MSTs have applications everytime someone needs to design an efficient grid. Examples for this might be electric grids, road grids or water pipe grids. \nBesides that, MSTs can be used for studying epidemeology by finding the shortest paths trough which pathogens might traverse a population network.\n\nIn biological research, MFTs might be used for visualization or clustering purposes. An example for this can be seen in the picture below, where phylogenetic groups were found and visualized using an MST.\n\n\u003Cimg src=\u0022https://upload.wikimedia.org/wikipedia/commons/thumb/d/d2/Minimum_spanning_tree.svg/1200px-Minimum_spanning_tree.svg.png\u0022 alt=\u0022drawing\u0022 width=\u002245%\u0022/\u003E\n\u003Cimg src=\u0022https://www.researchgate.net/profile/Michel-Fabre-2/publication/234090394/figure/fig11/AS:341854030712841@1458515760884/Minimum-spanning-tree-based-upon-whole-genome-SNP-analysis-The-tree-is-based-upon-13382.png\u0022 alt=\u0022drawing\u0022 width=\u002245%\u0022/\u003E\n\n\u003Cbr\u003E\n\nSeveral algorithms exist for finding MST, where often there is a tradeoff made between performance and quality of the result. Your task will be to implement one of them.\n\n## Aim for this project\n\n\u003Cbr\u003E\n\n- Get a basic understanding of network science\n\n- Implement Prim\u0027s algorithm for finding minimum spanning trees\n\n- Write a blogpost entry \n\n## Prim\u0027s algorithm\n\nPrim\u0027s algorithm is a simple, greedy approach for finding the MST of a network. Greedy approaches always find the best solution in exchange for lower performance. \n\nIn Prim\u0027s algorithm, you start a new graph by selecting a single vertex in the original graph. This new graph is repetitively grown by finding the closest connections to vertices not yet included in the MST.\n\n![prims](https://upload.wikimedia.org/wikipedia/commons/9/9b/PrimAlgDemo.gif)\n\n## References\n\n- [Introduction to graphs and networks](http://networksciencebook.com/chapter/2#networks-graphs)\n- [Minimum spanning tree](https://en.wikipedia.org/wiki/Minimum_spanning_tree)\n- [Prim\u0027s algorithm](https://en.wikipedia.org/wiki/Prim%27s_algorithm)\n- [Graph Visualization](https://fslab.org/Cyjs.NET/)\n\n## Coding clues\n\n### General steps:\n\n1. Initialize a tree with a single vertex, chosen arbitrarily from the graph.\n2. Grow the tree by one edge: of the edges that connect the tree to vertices not yet in the tree, find the minimum-weight edge, and transfer it to the tree.\n3. Repeat step 2 (until all vertices are in the tree).\n\n### Using the graph library:\n\n*)\n\n#r \u0022nuget: FSharp.FGL\u0022 \n\nopen FSharp.FGL\nopen FSharp.FGL.Undirected\n\n// Create a new graph\nlet g : Graph\u003Cint,string,float\u003E = Graph.empty\n\n\n// Add vertices \nlet v1 = (1,\u0022VertexNumeroUno\u0022)\nlet v2 = (2,\u0022VertexNumeroDos\u0022)\n\nlet gWithVertices = \n    Vertices.add v1 g\n    |\u003E Vertices.add v2\n\n// Add edges\nlet e = (1,2,1.)\n\nlet gWithEdge = \n    Edges.add e gWithVertices\n\n// Show all edges to find the best\nEdges.toEdgeList\n\n// Remove vertex (Including its edges)\nVertices.remove (fst v1) gWithEdge\n\n(**\n### Visualize the graph:\n*)\n\n#r \u0022nuget: Cyjs.NET\u0022\n\nopen Cyjs.NET\n\nlet inline toCyJS (g : Graph\u003C\u0027Vertex,\u0027Label,float\u003E) =\n    let vertices = \n        g\n        |\u003E Vertices.toVertexList\n        |\u003E List.map (fun (id,name) -\u003E Elements.node (string id) [CyParam.label (string name)])\n\n    let edges =\n        g\n        |\u003E Edges.toEdgeList\n        |\u003E List.map (fun (v1,v2,weight) -\u003E Elements.edge (string v1 \u002B string v2) (string v1) (string v2) [CyParam.weight (weight)])\n\n    CyGraph.initEmpty ()\n    |\u003E CyGraph.withElements vertices\n    |\u003E CyGraph.withElements edges\n    |\u003E CyGraph.withStyle \u0022node\u0022 [CyParam.content =. CyParam.label]\n    |\u003E CyGraph.withStyle \u0022edge\u0022 [CyParam.content =. CyParam.weight]\n\n(***do-not-eval***)\ngWithEdge\n|\u003E toCyJS\n|\u003E CyGraph.show\n\n(**\n\u003Cbr\u003E\n\n#### The visualized graph should look as follows:\n*)\n\n(*** hide ***)\ngWithEdge\n|\u003E toCyJS\n|\u003E CyGraph.withSize(600, 400) \n|\u003E Cyjs.NET.HTML.toEmbeddedHTML\n(*** include-it-raw ***)"},{"uri":"/BIO-BTE-10-L-4/projects/hClust.html","title":"Efficient agglomerative hierarchical clustering","content":"(**\n---\ntitle: Efficient agglomerative hierarchical clustering\ncategory: projects\ncategoryindex: 1\nindex: 2\n---\n*)\n\n\n(**\n# Implementation of an efficient hierarchical agglomerative clustering algorithm\n\n**Interested?** Contact [muehlhaus@bio.uni-kl.de](mailto:muehlhaus@bio.uni-kl.de) or [venn@bio.uni-kl.de](mailto:venn@bio.uni-kl.de)\n\n#### Table of contents\n\n#### Table of contents\n\n- [Introduction](#Introduction) \n- [Aim for this project](#Aim-for-this-project)\n- [Coding clues](#Coding-clues)\n    - [Step 0](#0-sup-th-sup-step)\n    - [Step 1](#1-sup-st-sup-step)\n    - [Step 2 - generate priority queue](#2-sup-nd-sup-step-Generate-priority-queue)\n    - [Step 3](#3-sup-rd-sup-step)\n    - [Step 4](#4-sup-th-sup-step)\n    - [Step 5](#5-sup-th-sup-step)\n    - [Step 6 - Function implementation in F#](#6-sup-th-sup-step-Function-implementation-in-F)\n    - [Step 7 - Further coding considerations](#7-sup-th-sup-step-Further-coding-considerations)\n- [References](#References)\n- [Additional information](#Additional-information)\n    - [Testing](#Testing)\n    - [Blog post](#Blog-post)\n\n\n## Introduction\n\n![](../img/overview.png)\n\nFig 1: Generating a hierarchical tree structure from a complex data set. Vertical thresholds (yellow, green, violet) generate different cluster numbers.\n\nClustering methods can be used to group elements of a huge data set based on their similarity. Elements sharing similar properties cluster together and can be \nreported as coherent group. These properties could be e.g. (a) similar gene expression kinetics in time series, (b) similar physicochemical properties, (c) genetic \nsimilarity measures for phylogenetic trees, etc.\n\nMany clustering algorithms require a predefined cluster number, that has to be provided by the experimenter. The most common approach is _k_-means clustering, \nwhere _k_ stands for the user defined cluster number. This kind of user interaction can lead to results, that are not objective, but highly influenced by the \nview and expectation of the experimenter. \n\nHierarchical clustering (_hClust_) does not require such cluster number definition. Instead, _hClust_ reports all possible cluster numbers \n(One big cluster with all elements to n clusters where every element is a singleton in its own cluster) in a tree structure (Fig 1). \nA _hClust_ tree has a single cluster (node) on its root and recursively splits up into clusters of elements that are more similar to each other than \nto elements of other clusters. For generating multiple cluster results with different number of clusters, the clustering has to performed only once. \nSubsequently the tree can be cut at any vertical line which will result in a defined number of clusters.\n\nThere are two types of _hClust_: \n\n  - Agglomerative (bottom-up): Each data point is in its own cluster and the nearest ones are merged recursively. It is referred to agglomerative hierarchical clustering (_HAC_)\n\n  - Divisive (top-down): All data points are in the same cluster and you divide the cluster into two that are far away from each other.\n\n  - The presented implementation is an agglomerative type.\n\n\nThere are several distance metrics, that can be used as distance function. The commonly used one probably is Euclidean distance. By inverting the distance, you end up with a similarity. High similarities indicate low distances, and vice versa. By calculating the similarities for every element pair, a similarity matrix can be generated.\n\n![](../img/simMatrix.png)\n\nFig 2: Data matrix (left) with measurement types as columns and (biological) entities as rows. The data matrix can be converted into a similarity matrix, that contain the inverse of distances.\n\n![](../img/workflow.png)\n\nFig 3: Workflow as proposed in pseudo code in Reference#2. \n\n\n## Aim for this project\n\n1. Blog post introducing the method, its applications, and limitations.\n\n2. Implement an efficient agglomerative hierarchical clustering in FSharp.Stats.\n\n\n## Coding clues\n\n### 0\u003Csup\u003Eth\u003C/sup\u003E step: \n\n  - Inform yourself about \n\n    - queues and priority queues (roughly)\n\n    - similarity measurements such as Euclidean distance, Manhattan distance, the advantage to use the squared Euclidean distance\n\n    - single linkage, complete linkage, and centroid based linkage types\n\n  - Down below you can see the pseudo code (not F#!) the efficient agglomerative hierarchical clustering (_HAC_) is based on:\n\n    \u0060\u0060\u0060\n    // Generating priority queue\n    Q = [] //priority queue \n    for n = 1 to N \n        for i = 1 to N \n            Q.enqueue(SIM(d[i], d[n]), (i, n)) \n    \n    // iterative agglomerative clustering\n    for k = 1 to N-1 \n        \u003Ci,m\u003E = Q.dequeue() \n        mergedCluster = merge((i,m)) \n    \n        Q.remove((_,m)) //remove any similarity that includes m \n    \n        for j = 1 to N \n            Q.update((i,j), SIM(mergedCluster, d[j])) \n    \u0060\u0060\u0060\n\n\n### 1\u003Csup\u003Est\u003C/sup\u003E step: \n\n  - create a F# script (.fsx), load and open \u0060\u0060\u0060FSharp.Stats\u0060\u0060\u0060, \u0060\u0060\u0060FSharpAux\u0060\u0060\u0060 and \u0060\u0060\u0060FSharpx.Collections\u0060\u0060\u0060\n\n  - import test data\n\n    - You can find the classic clustering dataset \u0022iris\u0022 [here](https://github.com/fslaborg/FSharp.Stats/tree/developer/docs/data).\n\n  - An implementation of an priority queue is given below.\n*)\n\n(******)\n\n#r \u0022nuget: FSharp.Stats, 0.4.1\u0022\n#r \u0022nuget: FSharpAux, 1.0.0\u0022\n#r \u0022nuget: FSharpx.Collections, 2.1.3\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-beta9\u0022\n            \nopen FSharp.Stats\nopen FSharpAux\nopen FSharpx.Collections\nopen Plotly.NET\n\n                \nlet lables,data =\n    let fromFileWithSep (separator:char) (filePath) =     \n        // The function is implemented using a sequence expression\n        seq {   let sr = System.IO.File.OpenText(filePath)\n                while not sr.EndOfStream do \n                    let line = sr.ReadLine() \n                    let words = line.Split separator//[|\u0027,\u0027;\u0027 \u0027;\u0027\\t\u0027|] \n                    yield words }\n    fromFileWithSep \u0027,\u0027 (__SOURCE_DIRECTORY__ \u002B \u0022../content/irisData.csv\u0022)\n    |\u003E Seq.skip 1\n    |\u003E Seq.map (fun arr -\u003E arr.[4], [| float arr.[0]; float arr.[1]; float arr.[2]; float arr.[3]; |])\n    |\u003E Seq.toArray\n    |\u003E FSharp.Stats.Array.shuffleFisherYates\n    |\u003E Array.mapi (fun i (lable,data) -\u003E sprintf \u0022%s_%i\u0022 lable i, data)\n    |\u003E Array.unzip\n\n    \ntype PriorityQueue\u003C\u0027T when \u0027T : comparison\u003E(values : \u0027T [], comparisonF : \u0027T -\u003E float) = \n        \n    let sort = Array.sortByDescending comparisonF\n    let mutable data = sort values \n    \n    new (comparisonF) = PriorityQueue(Array.empty,comparisonF)\n    \n    interface System.Collections.IEnumerable with\n        member this.GetEnumerator() = data.GetEnumerator()\n    \n    member this.UpdateElement (t:\u0027T) (newt:\u0027T) =     \n        let updated =\n            data \n            |\u003E Array.map (fun x -\u003E if x = t then newt else t)\n            |\u003E sort\n        data \u003C- updated\n          \n    member this.Elements = data\n        \n    member this.RemoveElement (t:\u0027T) = \n        let filtered = \n            Array.filter (fun x -\u003E x \u003C\u003E t) data\n        data \u003C- filtered\n    \n    member this.GetHead :\u0027T = \n        Array.head data\n    \n    member this.Dequeue() = \n        let head,tail = Array.head data, Array.tail data\n        data \u003C- tail\n        head, this\n    \n    member this.Insert (t:\u0027T) = \n        let newd = Array.append data [|t|] |\u003E sort\n        data \u003C- newd\n\n    member this.UpdateBy (updateElementFunction: \u0027T -\u003E \u0027T) = \n        let newd = \n            Array.map updateElementFunction data \n            |\u003E sort\n        data \u003C- newd\n\n    member this.RemoveElementsBy (predicate: \u0027T -\u003E bool) = \n        let newd = \n            Array.filter predicate data \n        data \u003C- newd\n\n(**\n### 2\u003Csup\u003End\u003C/sup\u003E step: Generate priority queue\n\n  - For each data point calculate the distances to each of the other points. \n\n    - You can find different kinds of distance measures in \u0060\u0060\u0060ML.DistanceMetrics\u0060\u0060\u0060\n\n    - Similarity can be interpreted as inverse distance. The lower the distance, the higher the similarity and the faster the data points have to be merged. \n    An appropriate type to store the result could be the following:\n\n*)\n\n(******)\n\n/// Type to store similarities\ntype Neighbour = {\n    /// inverse of distance\n    Similarity: float\n    /// list of source cluster indices\n    Source  : int list\n    /// list of target cluster indices\n    Target  : int list\n    }\n    with static\n            member Create d s t = { Similarity = d; Source = s; Target = t}\n\n//Example queue\nlet neighbours = \n    [|\n    Neighbour.Create 1. [1]      [2]\n    Neighbour.Create 2. [0]      [6]\n    Neighbour.Create 5. [3]     [5]\n    Neighbour.Create 2. [4;7;10] [8;9]\n    Neighbour.Create 7. [1]      [2]\n    |]\n\n////// usage of PriorityQueue\nlet myPQueue = PriorityQueue(neighbours,fun x -\u003E x.Similarity)\nmyPQueue.GetHead                                                                     // reports queues\nmyPQueue.RemoveElement (Neighbour.Create 5. [3] [5])                                 // removes element from queue\nmyPQueue.UpdateElement (Neighbour.Create 2. [0] [6]) (Neighbour.Create 200. [0] [6]) // update element in queue \nmyPQueue.RemoveElementsBy (fun x -\u003E not (List.contains 3 x.Source))                  // update element in queue \nmyPQueue.UpdateBy (fun x -\u003E if x.Similarity \u003E 2. then Neighbour.Create 100. x.Source x.Target else x)// update elements in queue  by given function\n\n////// usage of IntervalHeap\n#r \u0022nuget: C5, 2.5.3\u0022\nopen C5\nlet myHeap : IntervalHeap\u003CNeighbour\u003E = IntervalHeap(MemoryType.Normal)\n\nmyHeap.AddAll(neighbours)                   // adds array of neighbours\nlet max = myHeap.FindMax()                  // finds max value entry\nmyHeap.DeleteMax()                          // deletes max value entry \nmyHeap.Filter (fun x -\u003E x.Similarity = 5.)  // filters entries based on predicate function\n\n\n(**\n  - Some example applications of the PriorityQueue type are shown above.\n  \n  - Generate a priority queue that is descending regarding the similarity. \n\n\n### 3\u003Csup\u003Erd\u003C/sup\u003E step:\n  - Create a clustering list, that contains information of the current clustering state. This could be an \u0060\u0060\u0060int list []\u0060\u0060\u0060 where each of the lists contains indices of clustered data points. Since in the beginning all data points are in its own cluster the clustering list could look as follows: \n\n    - \u0060\u0060\u0060let clusteringList = [|[0];[1];[2];...[n-1]|]\u0060\u0060\u0060\n\n  - When cluster 1 and 2 merge, the clustering list may look like this:\n\n    - \u0060\u0060\u0060let clusteringList = [|[0];[1;2];[];...[n-1]|]\u0060\u0060\u0060\n\n### 4\u003Csup\u003Eth\u003C/sup\u003E step:\n  - Now the agglomeration starts. Since every data point is in its own cluster, you can perform n-1 agglomeration (merging) steps before you result in a single cluster that contains all data points.\n\n  - For each merge (1..n-1) do\n\n    - take the first entry of the priority queue (the most similar clusters)\n\n      - source indices = [i] \n\n      - target indices = [j]\n\n    - Create a new cluster, that contains the merged indices: [i;j]\n\n    - Save the new cluster configuration in your clustering list. Therefore you can add j to the i\u003Csup\u003Eth\u003C/sup\u003E cluster, and you can remove j from the j\u003Csup\u003Eth\u003C/sup\u003E cluster.\n\n    - Remove any entry from priority queue that contains j as target or source index.\n\n    - Update all entries in priority queue that contain i as source or targe index:\n\n      - j has to be added to every cluster that contains i\n\n      - Replace the distances with new distances of the merged mergedCluster to all other clusters.\n\n    - repeat cycle with next merge\n\n### 5\u003Csup\u003Eth\u003C/sup\u003E step:\n\n  - Clustering list now contains all possible cluster configurations. Convert the clustering list into\n  a binary tree structure such as \u0060\u0060\u0060ML.Unsupervised.HierarchicalClustering.Cluster\u003C\u0027a\u003E\u0060\u0060\u0060\n\n\n### 6\u003Csup\u003Eth\u003C/sup\u003E step: Function implementation in F#\n\n  - create a function, that contains all necessary helper functions in its body and takes the following parameters (suggestion):\n\n|Parameter name|data type|description|\n|--------------|---------|-----------|\n|data|\u0060\u0060\u0060seq\u003C\u0027a\u003E\u0060\u0060\u0060|data|\n|distFu|\u0060\u0060\u0060\u0027a-\u003E\u0027a-\u003Efloat\u0060\u0060\u0060|distance Function from \u0060\u0060\u0060FSharp.Stats.ML.DistanceMetrics\u0060\u0060\u0060|\n|linkageType|\u0060\u0060\u0060Linker.LancWilliamsLinker\u0060\u0060\u0060 or self defined|linkage type that is used during clustering|\n||||\n|output|\u0060\u0060\u0060ML.Unsupervised.HierarchicalClustering.Cluster\u003C\u0027a\u003E\u0060\u0060\u0060 or cluster configuration list||\n\n### 7\u003Csup\u003Eth\u003C/sup\u003E step: Further coding considerations\n\n  - Removing elements from the priority queue is slow. Is there a better way to avoid the deletion? \n  \n    - maybe a Map(int[],bool), or a nested priority queue (see Reference#2) would be beneficial\n\n    - or another implementation of heap/priority queues like C5.IntervalHeap could be faster\n\n## References\n\n- https://www.youtube.com/watch?v=7xHsRkOdVwo\n\n- https://github.com/srirambaskaran/efficient-hierarchical-clustering\n\n- https://nlp.stanford.edu/IR-book/pdf/17hier.pdf\n\n- https://medium.com/machine-learning-researcher/clustering-k-mean-and-hierarchical-cluster-fa2de08b4a4b\n\n\n## Additional information\n\n### Testing\n\n  - apply hClust to a dataset of your choice\n\n  - optional: Test your results against implementations in R/Python or in the best case against the datasets proposed in the original publication.\n\n### Blog post\n\n  - What is solved by the usage of hClust?\n  \n  - classical application examples\n  \n  - limitations/drawbacks of hClust\n\n  - short description of the algorithm (maybe with flowchart visualization)\n\n\n*)"},{"uri":"/BIO-BTE-10-L-4/projects/evolutionary-distance.html","title":"Phylogenetic tree reconstruction based on evolutionary distance","content":"(**\n---\ntitle: Phylogenetic tree reconstruction based on evolutionary distance\ncategory: projects\ncategoryindex: 1\nindex: 3\n---\n*)\n\n(**\n# Phylogenetic tree reconstruction based on evolutionary distance\n    \n**Interested?** Contact [muehlhaus@bio.uni-kl.de](mailto:muehlhaus@bio.uni-kl.de) or [schneike@bio.uni-kl.de](mailto:schneike@bio.uni-kl.de)\n\n#### Table of contents\n\n- [Introduction](#Introduction) \n    - [Phylogenetic trees](#Phylogenetic-trees)\n    - [Evolutionary Distance of DNA sequences](#Evolutionary-Distance-of-DNA-sequences)\n        - [Proportional distance](#Proportional-distance)\n    - [Distance Corrections based on evolutionary Models](#Distance-Corrections-based-on-evolutionary-Models)\n        - [The Jukes-Cantor Model](#The-Jukes-Cantor-Model)\n        - [The Kimura 2-Parameter Model](#The-Kimura-2-Parameter-Model)\n- [Aim for this project](#Aim-for-this-project)\n- [Coding clues](#Coding-clues)\n    - [Before you start](#Before-you-start)\n    - [Scripting environment and necessary libraries](#Scripting-environment-and-necessary-libraries)\n    - [General coding advice](#General-coding-advice)\n- [References](#References)\n- [Additional information](#Additional-information)\n\n## Introduction\n\n### Phylogenetic trees\n\nPhylogenetic trees are diagrams that visualize inferred evolutionary relationships between a set of organisms. Consider this tree diagram:\n\n\u0060\u0060\u0060\n         ____ A\n       _|\n      | |____ B\n______|\n      |______ C\n\u0060\u0060\u0060\n\nAncestors are shown as nodes on the tree, while the leaves represent the respective organisms.\nIt tells you that A and B share a common ancestor, and that that ancestor shares a common ancestor with C. \nIn other words, A and B are closer related to each other, than each of them to C.\n\nA and B form a _clade_ together with their common ancestor (also known as a _monophyletic group_) - a group of organisms that includes a single ancestor \nand all of its descendents that represent unbroken lines of evolutionary descent. \n\nBut based on what information do we construct such trees? There are different classes of approaches to this problem, but to stay beginner-friendy, \nonly _distance-based_ methods will be discussed in the scope of this project. For sake of completeness, other approaches include _parsimony_, \n_maximum likelihood_ and _Bayesian approaches_ to searching the possible tree space.\n\nThe first step in any (distance-based) phylogenetic tree reconstruction is the selection of the characteristic to infer evolutionary relationships from, \nand subsequently the determination of the phylogenetic distance between the organisms of interest based on that characteristic.\n\n\u003Cbr\u003E\n\n---\n\n### Evolutionary Distance of DNA sequences\n\nAny kind of characteristic of organisms can be used to try to infer phylogenetic relationships - like for example beaks of Darwin finches -\nbut DNA sequences have proven to be incredibliy helpful to reconstruct phylogenetic trees, as the nucleotide alphabet is relatively \nsimple and sequencing data has reached unparalleled throughput and accuracy. Likewise, there are a wide range of sophisticated methods to \ncalculate phylogenetic distance based on DNA sequences. \n\nIn the scope of this project, you will take a step back and look at some classic evolutionary models that can be used to model phylogenetic \ndistance based on DNA sequences.\n\nA few important bits of jargon for the following chapters:\n\n- DNA substitution mutations can be classified by 2 types:\n    - _Transitions_ are interchanges of two-ring purines (A \u003C\u003E G) or of one-ring pyrimidines (C \u003C\u003E T)\n    - _Transversions_ are interchanges of purine for pyrimidine bases or vice versa (A \u003C\u003E T | A \u003C\u003E C | G \u003C\u003E T | G \u003C\u003E C)\n\n\u003Cimg style=\u0022max-width:30%\u0022 src=\u0022../img/transitions-transversions.svg\u0022\u003E\u003C/img\u003E\n\n\u003Cbr\u003E\n\n---\n\n#### Proportional distance\n\nThe pairwise proportional distance (or _p distance_) is the classical \u0027naive\u0027 approach to estimate pairwise distances between two sequences. \n\nIt is simply the ratio between substitution sites and the length of the sequences. Note that - as in all distances you will implement - both \nsequences have to be of the same length or have to be aligned before calculating distances. It is obtained by dividing the amount of substitutions \nby the total amount of compared nucleotides:\n\n$p = \\frac{d}{L},$\n\nwhere \n\n$d = s \u002B v$\n\n$s : Transitions$\n\n$v : Transversions$\n\n$L : length$\n\nWhat are the advantages and weaknesses of this approach? Inform yourself.\n\n\u003Cbr\u003E\n\n---\n\n### Distance Corrections based on evolutionary Models\n\nTo overcome the shortcomings of the simple proportional distance, many evolutionary models for biological sequences are available.\nMost of the time, sequence evolution by mutation is described as a stochastic process modelled by continuous-time Markov chains, with \nthe alphabet (for DNA: _A, C, G, T_) as possible states.\n\nFor any sequence position, these models are then defining a substitution probability matrix based that acts as the stochastic matrix of the markov chain.\n\nA basic understanding of markov chains may be beneficial, but not necessary. It is just important that these models define probabilities \nfor transitions and transversions, and can be solved for a corrected pairwise distance that suffices the model substitution criteria.\n\n\u003Cbr\u003E\n\n---\n\n#### The Jukes-Cantor Model\n\nThe Jukes-Cantor model is the simplest form of these kinds of models. It makes no difference between transitions and transversions, \nmeaning that all substitutions have the same substitution rate ($\\alpha$). Also, all sites are modelled independently.\n\nThe substitution matrix is:\n\n$$$\n\\begin{matrix}\n\u0026 \\begin{matrix}A \u0026 \u0026 C \u0026 \u0026 G \u0026 \u0026 T\\end{matrix} \\\\\\\\\n\\begin{matrix}A\\\\\\\\C\\\\\\\\G\\\\\\\\T\\end{matrix} \u0026 \n  \\begin{pmatrix}\n    -3\\alpha\u0026\\alpha\u0026\\alpha\u0026\\alpha\\\\\\\\\n    \\alpha\u0026-3\\alpha\u0026\\alpha\u0026\\alpha\\\\\\\\\n    \\alpha\u0026\\alpha\u0026-3\\alpha\u0026\\alpha\\\\\\\\\n    \\alpha\u0026\\alpha\u0026\\alpha\u0026-3\\alpha\n  \\end{pmatrix}\\\\\\\\\n\\end{matrix}\n\n$3\\alpha t$ mutations would be expected during a time $t$ for each sequence site on each sequence, leading to\na correction factor for the proportional distance $d_{JC}$ :\n\n$$d_{JC}=-\\frac{3}{4}ln(1-\\frac{4}{3}p)$$\n\nWhat are the advantages and weaknesses of this approach? Inform yourself.\n\n\u003Cbr\u003E\n\n\n\n---\n\n#### The Kimura 2-Parameter Model\n\nThe substitution matrix is:\n\n$$$\n\\begin{matrix}\n\u0026 \\begin{matrix}A \u0026 \u0026 \u0026 \u0026 C \u0026 \u0026 \u0026 \u0026 G \u0026 \u0026 \u0026 \u0026 T\\end{matrix} \\\\\\\\\n\\begin{matrix}A\\\\\\\\C\\\\\\\\G\\\\\\\\T\\end{matrix} \u0026 \n  \\begin{pmatrix}\n    -2\\beta-\\alpha\u0026\\beta\u0026\\alpha\u0026\\beta\\\\\\\\\n    \\beta\u0026-2\\beta-\\alpha\u0026\\beta\u0026\\alpha\\\\\\\\\n    \\alpha\u0026\\beta\u0026-2\\beta-\\alpha\u0026\\beta\\\\\\\\\n    \\beta\u0026\\alpha\u0026\\beta\u0026-2\\beta-\\alpha\n  \\end{pmatrix}\\\\\\\\\n\\end{matrix}\n\nIt results in a corrected distance $d_{K2P}$:\n\n$d_{K2P}=-\\frac{1}{2}ln(1-2P-Q)-\\frac{1}{4}ln(1-2Q)$,\n\nwhere\n\n$P=\\frac{s}{L}$\n\n$Q=\\frac{v}{L}$\n\nWhat are the advantages and weaknesses of this approach? Inform yourself.\n\n\u003Cbr\u003E\n\n---\n\n## Aim for this project\n\nYou understand the following evolutionary distance models and are able to explain the differences between them (required in your final report)\nAlso, you implement them in F# for the BioFSharp library:\n\n- Pairwise p Distance\n- JC69 evolutionary distance based on the model by Jukes and Cantor\n- K81 evolutionary distance based on the Kimura two-parameter model\n\nAs a demonstration of your implementations, as well as to show the differences between these models,\nYou construct at least 10 adequate test sequences of equal length, and construct phyologenetic trees from them. \nInvestigate the most interesting and obvious differences, and relate them to the different model assumptions.\n\nFinally, you choose adequate sequences of at least 6 organisms, perform a multiple alignment for them and repeat above process for real-world sequences.\n\n**Bonus**: You implement a visualization method for phylogenetic trees for [Cyjs.NET](). \n\n## Coding clues\n\n### Before you start \n\n- (re)familiarize yourself with the basics behind phylogenetic trees.\n\n- (re)familiarize yourself with F# function signatures and the basics of F# programming.\n\n- A basic understanding of Markov chains is beneficial, but not necessary.\n\n### Scripting environment and necessary libraries\n\n- create a F# script (.fsx), load and open the following libraries:\n    - \u0060FSharpAux\u0060\n    - \u0060FSharpAux.IO\u0060\n    - \u0060FSharp.Stats\u0060\n    - \u0060BioFSharp\u0060\n    - \u0060BioFSharp.IO\u0060\n    - \u0060Plotly.NET\u0060\n\nthe top of your script file should look like this:\n*)\n\n#r \u0022nuget: FSharpAux\u0022\n#r \u0022nuget: FSharpAux.IO\u0022\n#r \u0022nuget: FSharp.Stats, 0.4.1\u0022 \n#r \u0022nuget: BioFSharp, 2.0.0-beta6\u0022\n#r \u0022nuget: BioFSharp.IO, 2.0.0-beta6\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-beta9\u0022\n\nopen FSharpAux\nopen FSharpAux.IO\nopen BioFSharp\nopen BioFSharp.IO\nopen FSharp.Stats\nopen Plotly.NET\n\n(**\n\n### General coding advice\n\n- All pairwise distance functions should be able to operate on either \u0060BioArray\u0060, \u0060BioList\u0060, or \u0060BioSeq\u0060. \nYou can use the fact that all of these sequence types are implementing \u0060IEnumerable\u0060 and can only contain nucleotides.\n\n\u003Cbr\u003E\n\n---\n\n- To perform hierarchical clustering to reconstruct the phylogenetic trees, use the respective module from the \u0060BioFSharp\u0060 library \n(\u0060PhylogeneticTree\u0060 functions) and work with \u0060TaggedSequence\u0060s:\n\n\u003Cbr\u003E\n\n*)\n\n(***do-not-eval***)\nopen BioFSharp\n\n(***do-not-eval***)\nlet yourDistance (seqA: seq\u003CIBioItem\u003E) (seqB:seq\u003CIBioItem\u003E) = ...\n\n(***do-not-eval***)\n//reconstruct a phylogenetic tree from tagged sequences\nlet myTree =\n    PhylogeneticTree.ofTaggedBioSequences\n        yourDistance // your distance function for either p, JC69, or K81 distance\n        yourSequences // your adequate nucleotide test sequences as tagged sequences \n\n(**\n\u003Cbr\u003E\n\n---\n\n- to perform Multiple sequence alignment between your real world sequence examples, use the respective functions from \u0060BioFSharp\u0060:\n\n    For that, you have to first install [clustal omega](http://www.clustal.org/omega/clustal-omega-1.2.2-win64.zip), a very nice multiple sequence aligment tool. \n    You can use it directly in F# interactive via BioFSharp\u0027s \u0060ClustalOWrapper\u0060:\n\n\u003Cbr\u003E\n\n*)\n\nopen ClustalOWrapper\nlet cw = ClustalOWrapper(\u0022path/where/you/extracted/clustal-omega-1.2.2-win64/clustalo.exe\u0022) // replace with real path from your machine here!\n\nlet sequences = \n    [\n    TaggedSequence.create \u0022seq1\u0022 (\u0022ATGAAAAA\u0022)\n    TaggedSequence.create \u0022seq2\u0022 (\u0022ATGAAACA\u0022)\n    TaggedSequence.create \u0022seq3\u0022 (\u0022ATGAAAAAAT\u0022)\n    TaggedSequence.create \u0022seq4\u0022 (\u0022ATGGAAAA\u0022)\n    ]\n\nlet alignedSequences = \n    cw.AlignSequences(sequences,Seq.empty)\n\n(**\n\u003Cbr\u003E\n\n---\n\n- There are two ways of handling the gaps produced by alignments: _Complete-Deletion_ and _Pairwise Deletion_ inform yourself about them.  \n\n    _Hint1_: The output of above alignment contains conservation information about the alignment. \n\n    _Hint2_: You might want to add an additional parameter to your distance function modelling this behaviour. For that, use a Discriminated Union type.\n\n\u003Cbr\u003E\n\n---\n\n- Here is a suggestion for the general workflow for the real-world sequences:\n\n\u003E**Suggested workflow**\n\u003E\n\u003ERead your fasta formatted sequences\n\u003E\n\u003EPerform multiple sequence alignment $A$\n\u003E\n\u003Efor each implemented distance function $dist$:\n\u003E\n\u003E$\\quad$reconstruct phylogenetic tree for $A$ with $dist$ function\n\u003E\n\u003E$\\quad$Write as newick format\n\u003E\n\u003E$\\quad$Visualize tree, for example on http://etetoolkit.org/treeview/\n\n---\n\n*)\n\n\n(**\n\n---\n\n## References\n\nNei, M. \u0026 Zhang J. Evolutionary Distance: Estimation 2006 https://doi.org/10.1038/npg.els.0005108\n\nhttps://en.wikipedia.org/wiki/Models_of_DNA_evolution\n\nhttps://www.cs.rice.edu/~nakhleh/COMP571/Slides/Phylogenetics-DistanceMethods-Full.pdf\n\nhttps://www.megasoftware.net/mega1_manual/Distance.html\n\n## Additional information\n\n*)"},{"uri":"/BIO-BTE-10-L-4/projects/tSNE.html","title":"t-Distributed Stochastic Neighbour Embedding","content":"(**\n---\ntitle: t-Distributed Stochastic Neighbour Embedding\ncategory: projects\ncategoryindex: 1\nindex: 1\n---\n*)\n\n\n(**\n# t-Distributed Stochastic Neighbour Embedding (tSNE)\n\n**Interested?** Contact [muehlhaus@bio.uni-kl.de](mailto:muehlhaus@bio.uni-kl.de) or [venn@bio.uni-kl.de](mailto:venn@bio.uni-kl.de)\n\n#### Table of contents\n\n- [Introduction](#Introduction) \n- [Aim for this project](#Aim-for-this-project)\n- [Coding clues](#Coding-clues)\n    - [Notes](#Notes)\n    - [Pseudocode](#Pseudocode)\n    - [Step 0](#0-sup-th-sup-step)\n    - [Step 1](#1-sup-st-sup-step)\n    - [Step 2](#2-sup-nd-sup-step)\n    - [Step 3](#3-sup-rd-sup-step)\n    - [Step 4](#4-sup-th-sup-step)\n    - [Step 5](#5-sup-th-sup-step)\n    - [Step 6](#6-sup-th-sup-step)\n    - [Step 7](#7-sup-th-sup-step)\n    - [Step 8 - Function implementation in F#](#8-sup-th-sup-step-Function-implementation-in-F)\n- [References](#References)\n- [Additional information](#Additional-information)\n    - [Testing](#Testing)\n    - [Blog post](#Blog-post)\n\n## Introduction\n\n  - tSNE is a dimensionality reduction method. It allows you to visualise a multi-dimensional dataset in 2 or 3 dimensional scatter plot. \nBut what does that mean in practice? Imagine you measured height, weight, width, density, brightness, as well as magnetic, chemical, \nand physical properties of a bunch of objects. The simplest technique to summarize your measurements is a spreadsheet table in which each \nrow represents an element, and each column represents a measured feature:\n\n\n  |Object ID|height|weight|width|density|brightness|magnetic field|...|\n  |---------|------|------|-----|-------|----------|--------------|---|\n  |objectA|2|30|3|2|200|100000|...|\n  |objectB|4|50|2|3|255|130000|...|\n  |objectC|15|20|1|2|11|10000000|...|\n  |...|...|...|...|...|...|...|...|\n  \n\n  - Note that the measured features span multiple orders of magnitude. A change of 1 in height for example has much more value than a change \nof 1 regarding the magnetic field. If now clusters of similar behaving objects should be identified, you are limited to inspect the data set \ncolumn-wise by repetitive sorting. Just from the table you cannot create a meaningful graph, that allows you to perform a visual inspection of all features at once. \nLike principal component analysis (PCA), tSNE is a method for dimensionality reduction. It aggregates all features to a feature subset that \nallows a visual inspection of the complex data. It often is applied in image processing, NLP, genomic data, and speech processing. \n  \n  \n  ![](../img/tSNE.png)\n  Fig. 1: Idea of tSNE. Visualisation of a high dimensional data on a 2-dimensional scatter plot. \n  \n## Aim for this project\n\n1. Blog post introducing the method, its applications, and limitations.\n\n2. Implement t-Distributed Stochastic Neighbour Embedding in FSharp.Stats.\n\n  \n## Coding clues\n\n### Notes:\n\n  - All functions below are taken from the original publication (van der Maaten and Hinton 2008).\n\n  - Be aware, that the original work first describes SNE and later (section 3) describes the differences made to result in t-SNE!\n\n  - Although variance is continually referred to as \u03C3\u003Csub\u003Ei\u003C/sub\u003E in the paper, that is a repeated typo and should be \u03C3\u003Csub\u003Ei\u003C/sub\u003E\u003Csup\u003E2\u003C/sup\u003E.\n\n  - The data matrix has n rows (without header row). The first index defines the row, the second the column!\n\n  - x\u003Csub\u003Ei\u003C/sub\u003E defines the i\u003Csup\u003Eth\u003C/sup\u003E row in the data matrix (a vector of measured features).\n\n  - ||x|| indicates the vector norm, in this case it is the Euclidean distance between vector x\u003Csub\u003Ei\u003C/sub\u003E and y\u003Csub\u003Ei\u003C/sub\u003E. You can find distance metrics at \u0060\u0060\u0060FSharp.Stats.ML.DistanceMetrics\u0060\u0060\u0060.\n\n  - exp(t) indicates e\u003Csup\u003Et\u003C/sup\u003E\n\n  - A t distribution with degree of freedom = 1 is equal to 0.3183*(1\u002Bt\u00B2)-1 where the first constant part can be neglected if the constant term exists in all calculations.\n\n### Pseudocode:\n\n![](../img/tSNE_pc.png)\n\n#### 0\u003Csup\u003Eth\u003C/sup\u003E step: \n\n  - Read the publication and visit further introduction material you can find below (References)\n  \n#### 1\u003Csup\u003Est\u003C/sup\u003E step: \n\n  - create a F# script (.fsx), load and open \u0060\u0060\u0060FSharp.Stats\u0060\u0060\u0060, \u0060\u0060\u0060FSharpAux\u0060\u0060\u0060, and \u0060\u0060\u0060Plotly.NET\u0060\u0060\u0060\n\n  - import test data\n\n    - You can find the classic clustering dataset \u0022iris\u0022 [here](https://github.com/fslaborg/FSharp.Stats/tree/developer/docs/data).\n\n*)\n\n(******)\n\n#r \u0022nuget: FSharp.Stats, 0.4.1\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-beta9\u0022\n            \nopen FSharp.Stats\nopen Plotly.NET\n\n\nlet fromFileWithSep (separator:char) (filePath) =     \n    // The function is implemented using a sequence expression\n    seq {   let sr = System.IO.File.OpenText(filePath)\n            while not sr.EndOfStream do \n                let line = sr.ReadLine() \n                let words = line.Split separator//[|\u0027,\u0027;\u0027 \u0027;\u0027\\t\u0027|] \n                yield words }\n\n                \nlet lables,data =\n    fromFileWithSep \u0027,\u0027 (__SOURCE_DIRECTORY__ \u002B \u0022../content/irisData.csv\u0022)\n    |\u003E Seq.skip 1\n    |\u003E Seq.map (fun arr -\u003E arr.[4], [| float arr.[0]; float arr.[1]; float arr.[2]; float arr.[3]; |])\n    |\u003E Seq.toArray\n    |\u003E Array.shuffleFisherYates\n    |\u003E Array.mapi (fun i (lable,data) -\u003E sprintf \u0022%s_%i\u0022 lable i, data)\n    |\u003E Array.unzip\n\n\n(**\n\n#### 2\u003Csup\u003End\u003C/sup\u003E step:\n\n  - Calculate a Euclidean distance matrix using \u0060\u0060\u0060ML.DistanceMetrics.euclidean\u0060\u0060\u0060. The matrix\u2019 dimensions are n x n.\n  \n  - Define functions that calculate similarity measures using the prior defined distance matrix:\n    \n    - (1) high dimensional affinity p (p\u003Csub\u003Ei|j\u003C/sub\u003E)(Equation 1)\n\n      - Inform yourself how the variance is determined. If required define a Perplexity beforehand.\n\n    - (2) low dimensional affinity q (q\u003Csub\u003Eij\u003C/sub\u003E) (Equation 4)\n\n\n#### 3\u003Csup\u003Erd\u003C/sup\u003E step: \n\n  - Calculate the high dimensional affinity matrix between every data pair.\n\n    - Note: p\u003Csub\u003Eij\u003C/sub\u003E \u2260 p\u003Csub\u003Ei|j\u003C/sub\u003E\n\n    - p\u003Csub\u003Eij\u003C/sub\u003E = (p\u003Csub\u003Ej|i\u003C/sub\u003E \u002B p\u003Csub\u003Ei|j\u003C/sub\u003E) / 2n\n\n  - The matrix has the dimensions n x n . The similarity of a point to itself is 0.\n\n\n#### 4\u003Csup\u003Eth\u003C/sup\u003E step: \n\n  - Create an initial solution y(0) so that:\n\n    - y(0) is a matrix (n x d)\n\n    - y(0) contains as many rows as the original data matrix has rows (n)\n\n    - The number of values in each row is the number of dimensions you want to obtain in the end (d; in most cases 1-3, but should be defined by user).\n\n    - Each value is a randomly sampled from a normal distribution with mean = 0 and var = 0.0001.\n\n*)\n\n(******)\n\n// defines a normal distribuiton with mean = 3 and stDev = 2\nlet normalDist = Distributions.Continuous.normal 3. 2.\n\nlet createInitialGuess n = Array.init n (fun x -\u003E normalDist.Sample())\n\n// see FSharp.Stats documentation for probability distributions in the first code block for details\n// https://fslab.org/FSharp.Stats/Distributions.html#Normal-distribution)\n\n\n(**\n\n\n#### 5\u003Csup\u003Eth\u003C/sup\u003E step:\n\n  - Recursively loop from t=1 to T (number of iterations)\n\n\n  - calculate low dimensional affinities (q\u003Csub\u003Eij\u003C/sub\u003E (Equation 4)) for all low dimensional result vectors from 3\u003Csup\u003Erd\u003C/sup\u003E step. Collect results in a matrix (n x n).\n\n  - compute gradient (Equation 5)\n\n  - calculate the updated result y(t) and repeat.\n\n#### 6\u003Csup\u003Eth\u003C/sup\u003E step:\n\n  - report y(T) as final result\n\n#### 7\u003Csup\u003Eth\u003C/sup\u003E step:\n  \n  - Use a 2D and 3D scatter plot from Plotly.NET to visualize your result.\n\n#### 8\u003Csup\u003Eth\u003C/sup\u003E step: Function implementation in F#\n\n  - create a function, that contains all necessary helper functions in its body and takes the following parameters (suggestion):\n  \n  |Parameter name|data type|description|\n  |--------------|---------|-----------|\n  |data|\u0060\u0060\u0060matrix\u0060\u0060\u0060|datamatrix (cols=features, rows=elements)|\n  |dimensions|\u0060\u0060\u0060int\u0060\u0060\u0060|number of dimensions the final output data points have|\n  |maxIter|\u0060\u0060\u0060int\u0060\u0060\u0060|maximal number of iterations|\n  |perplexity|\u0060\u0060\u0060float\u0060\u0060\u0060|inform yourself if the perplexity should be defined by the user, or is calculated within the algorithm|\n  |learnRate|\u0060\u0060\u0060float\u0060\u0060\u0060|inform yourself|\n  |momentum|\u0060\u0060\u0060float\u0060\u0060\u0060|inform yourself|\n\n  - Default parameters should be given in the function description or as optional paramter.\n\n\n## References\n\n  - van der Maaten \u0026 Hinton; Visualizing Data using t-SNE (2008) [PDF](https://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf )\n\n  - https://www.youtube.com/watch?v=NEaUSP4YerM \n\n  - https://cran.r-project.org/web/packages/Rtsne/Rtsne.pdf page 5\n\n  - https://www.analyticsvidhya.com/blog/2017/01/t-sne-implementation-r-python/\n\n    - Note: Inform yourself if the variance in Step 4 is in fact based on t distribution or if at this point of the algorithm a standard gaussian normal distribution is used!\n\n  - https://www.datacamp.com/community/tutorials/introduction-t-sne\n\n\n## Additional information\n\n### Testing\n\n  - Apply tSNE to a dataset of your choice.\n\n  - optional: Test your results against implementations in R/Python or in the best case against the datasets proposed in the original publication.\n\n### Blog post \n\n  - Don\u2019t forget to describe the limits/weaknesses of the approach in your blog post.\n\n  - How to handle/preprocess ties?\n\n  - optional: Compare the method to PCA.\n\n*)\n\n"}]