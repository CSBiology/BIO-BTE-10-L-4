[{"uri":"/BIO-BTE-10-L-4/index.html","title":"BIO-BTE-10-L-4\n","content":"# BIO-BTE-10-L-4\n\n\u003Cbr\u003E\n\nDeutscher titel: **Wissenschaftliche Programmierung f\u00FCr Biolog*innen (Projektarbeit)**\n\nEnglish title: **Scientific Programming For Biologists (project work)**\n\nKIS: [BIO-BTE-10-L-4](https://www.kis.uni-kl.de/campus/all/event.asp?gguid=0xE21F6D88E774426AAF47627AB6FC59BB\u0026tguid=0xA0CC12CC38514E09833533E643742D94)\n\n**Credit Points (CP): 9**\n\n**Vorraussetzungen/Requirements:** [BIO-BTE-12-V-4](https://csbiology.github.io/BIO-BTE-12-V-4/)\n\n**Table of contents**\n\n\u003C!-- TOC --\u003E\n\n- [Kursbeschreibung(deutsch)](#kursbeschreibungdeutsch)\n    - [Ablauf](#ablauf)\n- [Course description(english)](#course-descriptionenglish)\n    - [Procedure](#procedure)\n\n\u003C!-- /TOC --\u003E\n\n## Kursbeschreibung(deutsch)\n\nSetzen Sie Ihre F\u00E4higkeiten mit einer individuellen Projektarbeit im Bereich der Bioinformatik in die Praxis um. M\u00F6gliche Projektthemen erstrecken sich \u00FCber das gesamte Spektrum der Bioinformatik von Algorithmus- bis zur Webdienstimplementierung. Besprechen sie ihre eigene Themenidee oder w\u00E4hlen Sie ein vorgeschlagenes Projekt f\u00FCr sich aus.\n\n### Ablauf\n\n- **Themenwahl**: Die angebotenen Projektarbeitsthemen k\u00F6nnen sie der Sidebar links entnehmen. Die jeweiligen Artikel geben bereits einen detailierten \u00DCberblick \u00FCber das Thema und verschiedene Hinweise und Tipps f\u00FCr deren Bearbeitung. \n\n- **Themenbearbeitung**: Nach einem Einf\u00FChrungsgespr\u00E4ch bearbeiten sie das Thema digital in Eigenregie. Die Literaturrecherche, das Suchen und Analysieren eventueller Referenzimplementationen, sowie das Implementieren ihrer L\u00F6sungen in F# sollten eigenst\u00E4ndig durchgef\u00FChrt werden. Wir stehen ihnen dabei nat\u00FCrlich bei technischen und/oder Verst\u00E4ndnisproblemen zur Verf\u00FCgung -\n\n    _[Optional]_ Um ihre Arbeit zu versionieren und leichter teilbar zu machen, empfiehlt sich die Einrichtung und Pflege eines [Repositories auf GitHub](https://guides.github.com/activities/hello-world/). Bei Interesse kann hier auch eine Einf\u00FChrung unsererseits erfolgen.\n\n- **Leistungsnachweis**: Der Leistungsnachweis erfolgt durch eine Nachbesprechung und ein Protokoll mitsamt Dokumentation und Anwendungsbeispiel des Projekts. Art und Pr\u00E4sentation des Protokolls kann abh\u00E4ngig vom Projekt leicht unterschiedlich sein, grunds\u00E4tzlich sollten Folgende Punkte aber immer beachtet werden:\n    - Einleitender Text zu Problemstellung, Themenfeld, etc. (hier gerne an der Projektvorstellung orientieren)\n    - Schritt-f\u00FCr-Schritt Erkl\u00E4rung der Implementation der Probleml\u00F6sung **mit Codebeispielen** im [_Blogpost Stil_]()\n    - Anwendungsbeispiel **mit Codebeispielen**\n\n## Course description(english)\n\nPut your skills into practice by working on an individual project work in the field of bioinformatics. Project topics span the range of bioinformatic application from algorithms to web service implementation. Discuss your own ideas as project topic or select a suggested project.\n\n### Procedure\n\ncoming soon"},{"uri":"/BIO-BTE-10-L-4/bachelor/molecular-evolution.html","title":"Molecular evolution of thermolabile proteins in microalgae","content":"(**\n---\ntitle: Molecular evolution of thermolabile proteins in microalgae \ncategory: bachelor thesis\ncategoryindex: 3\nindex: 1\n---\n*)\n\n\n(**\n# Molecular evolution of thermolabile proteins in microalgae \n\n**Interested?** Contact [muehlhaus@bio.uni-kl.de](mailto:muehlhaus@bio.uni-kl.de) or [venn@bio.uni-kl.de](mailto:venn@bio.uni-kl.de)\n\n\n\n### Table of contents\n\n- [Introduction](#Introduction) \n- [Description](#Description)\n- [Additional information](#Additional-information)\n- [References](#References)\n\n# Introduction\n\nThe bachelor thesis focuses on the analysis of evolutionary constrained proteins. It aims to investigate the evolutionary rates of proteins and identify a special kind of key-regulator-mechanism in acclimation responses. \n\nIf you think of evolution, you intentionally assume, that sequences tend to evolve to become more thermostable over time.\nBut what is the reason that some sequences seems to be hindered to evolve and are kept thermolabile?\nThe idea is that defolding or aggregation during heat stress is no damage at all events, but more like a mechanism to trigger some heat stress responses.\nOf course, this is not true for all aggregating proteins but maybe for some master key-regulators which have switch functions to (de)activate specific pathways if the cellular pool is suddenly depleted.\n\n## On the role of thermolabile proteins in microalgae\n\nMutations drive the evolutionary development. Simultaneously repair and quality check mechanisms prevent harmful mutations in the short term. Are there evolutionary mechanisms that prevent specific proteins from being mutated?\nThe substitution rate for chloroplastidic genes was calculated to be 3.3*10\u003Csup\u003E-10\u003C/sup\u003E, which is almost 10 times lower than in genes of nuclear genomes, probably because of the plastid homologous recombination machinery and the dynamics of chloroplast genomes. \nAre there proteins that are intentionally do not undergo stabilizing mutations and thereby are kept thermolabile? \n\nThe aim is to identify genes with low evolutionary rates by using the *K\u003Csub\u003Ea\u003C/sub\u003E/K\u003Csub\u003Es\u003C/sub\u003E ratio* (sometimes referred as d\u003Csub\u003EN\u003C/sub\u003E/d\u003Csub\u003ES\u003C/sub\u003E, which describes the evolutionary rate of a DNA sequence.\n  \n  - K\u003Csub\u003Ea\u003C/sub\u003E is calculated by dividing all nonsynonymous substitutions per nonsynonymous site, or in other words: the number of sites where an nonsynonymous amino acid substitution occurred per all sites at which a nonsynonymous substitution is possible\n    \n  - K\u003Csub\u003Es\u003C/sub\u003E is calculated by dividing all synonymous substitutions per synonymous site\n\n\u003Cimg style=\u0022max-width:70%\u0022 src=\u0022../img/evolution_master.png\u0022\u003E\u003C/img\u003E\n\n\u003Cbr\u003E\n\n\u003Cimg style=\u0022max-width:70%\u0022 src=\u0022../img/evolution_master3.png\u0022\u003E\u003C/img\u003E\n\n\u003Cbr\u003E\n\nThe ratio _k_ of nonsynonymous (K\u003Csub\u003Ea\u003C/sub\u003E) to synonymous (K\u003Csub\u003Es\u003C/sub\u003E) nucleotide substitution rates is an indicator of selective pressures on genes. \n\n  - _k_ \u003E 1: more nonsyn than syn mutations -\u003E positive darwinian selection; driving change\n  \n  - _k_ = 1: equal rate of mutations -\u003E neutral evolution\n\n  - _k_ \u003C 1: more syn than nonsyn mutations -\u003E negative/purifying selection; acting against change\n\n\n\nCandidates can be investigated by comparing mutation rates of all proteins over several species within the _Chlorophyta_ phylum and identify anomalies.\nThereby, proteins found in aggregates are of particular interest since these are thermolabile and hypothetically should be under evolutionary pressure to become more stable.\nIf there is an equal slow/negative selection of orthologs between species, it\u2019s a clue for thermolability as a mechanism rather than a damage. \nOf course, you have to consider, that a strong conservation may be due to preserving the proteins\u2019 function. Accordingly, you have to make sure to keep the proteins affinity/activity \nin mind that may require further investigation of mutants proposed by the result of the analysis.\n\n\n\u003Cimg style=\u0022max-width:70%\u0022 src=\u0022../img/evolution_master2.png\u0022\u003E\u003C/img\u003E\n\n\u003Cbr\u003E\n\n\n# Project outline\n\n  - collect various genomes from _Chlorophyta_ phylum\n    - various genomes are available upon request\n  - multiple sequence alignment of proteins using ClustalW\n  - Construction of an adequate substitution model since some mutations are far more likely than others.\n  - Check the evolution rate of the proteins across the phylum. If the evolution rate is equal (or equally low) for a specific protein, it may hint to a conserved strategy of the protein\n  - In previous work we identified transcripts that were up regulated while protein abundance decreased during heat acclimation. This anticorrelation points to specific regulatory role or thermolability.\n    - is there an overlap of both analysis?\n  - How is the ratio of silent/non silent mutations, especially in RubisCO activase? \n    - RubisCO activase aggregates during the first period of heat treatment leading to starch depletion and increased TAG-production due to increased free energy reduction equivalents from photosynthesis.\n    After the membrane remodelling the amount of RubisCO activase recovers.\n    - _Hemme, D., Veyel, D., M\u00FChlhaus, T [\u2026] Schroda M. (2014). Systems-Wide Analysis of Acclimation Responses to Long-Term Heat Stress and Recovery in the Photosynthetic Model Organism Chlamydomonas reinhardtii. The Plant cell 26, 4270-4297._\n    \n  \n## Questions to answer\n\n  - Is there a mechanism preserving proteins from becoming more thermostable?\n  \n  - Where does this constraint come from?\n\n    - Is this conservation due to preserving the enzymatic activity or to preserve thermolability of key regulators?\n  \n  - What is the benefit?\n\n    - Do affected proteins act as regulators for stress response?\n    \n    - Is there a requirement for a fast depletion? (reduced energy consumption and more free energy for stress responses)\n  \n  \n  \n\n# Additional information\n\n  - Silent mutations are not necessarily \u0027silent\u0027 because altered mRNA sequences may affect transcription, splicing procedures, mRNA transport or translation, even if the protein sequence is identical in the end.\n  Translation can be affected by differential codon usage.\n  - A further possibility to preserve a certain kind of thermolability is the requirement for sufficient flexibility to undergo conformational changes during its catalytic activity.\n\n\n\n# References\n\n  - How many nucleotide substitutions actually took place?, Jukes TH, 1990\n  - Evolutionary perspectives on protein structure, stability, and functionality, Goldstein Richard; in \u0027Biological Evolution and Statistical Physics\u0027, p 82, Springer 2001\n  - (Introductional) Was ist molekulare Evolution? Die molekulare Uhr; in FJ Ayala, Die gro\u00DFen Fragen Evolution, p 80,  DOI 10.1007/978-3-642-33006-3_10,\n  - (Introductional) 3.12 Molekulare Systematik, Zrzav\u00FDin et al.; in Evolution, p 199, Spektrum 2003\n  - Evolutionary Rates and Expression Level in Chlamydomonas, Popescu et al., 2005, 10.1534/genetics.105.047399\n  - (Introductional) Gene, Zufall, Selektion - Popul\u00E4re Vorstellungen zur Evolution und der Stand des WIssens, Veiko Krau\u00DF, Springer, 2014\n  - Codon substitution in evolution and the saturation of synonymoous changes, Gojobori, Genetics Society of America, 1983 \n  - POTION: an end-to-end pipeline for positive Darwinian selection detection in genome-scale data through phylogenetic comparison of protein-coding genes, Hongo et al., 2015\n  - Computational Modeling for Evolution of HSP90A Homologues, Datta et al., IJETTCS, 2017\n  - KaKs_Calculator 2.0: A Toolkit Incorporating Gamma-Series Methods and Sliding Window Strategies, Wang, GENOMICS PROTEOMICS \u0026 BIOINFORMATICS, 2010\n  - Statistical methods for detecting molecular adaptation, Yang \u0026 Bielawski, TREE, 2000\n  - Estimating Synonymous and Nonsynonymous Substitution Rates Under Realistic Evolutionary Models, Yang \u0026 Nielsen, 2000\n  - *Computing Ka and Ks with a consideration of unequal transitional substitutions, Zhang et al., BMC, 2006*\n  - *Determinants of the rate of protein sequence evolution, Zhang \u0026 Yang, Nature revies Genetics, 2015*\n  - http://bioinformatics.cvr.ac.uk/blog/calculating-dnds-for-ngs-datasets/\n  \n\n\n\n\n\n*)\n\n"},{"uri":"/BIO-BTE-10-L-4/general/example-blog-post.html","title":"Example blog post","content":"(**\n---\ntitle: Example blog post\ncategory: general\ncategoryindex: 1\nindex: 3\n---\n*)\n\n(**\n# Blog post title\n\n**Table of contents**\n\n## Introduction to the field\n\nThis is placeholder text with a [link](google.com). \n\nThis is **bold placeholder text**. \n\nThis is _italic placeholder text_. \n\nThis is _**bold and italic placeholder text**_. \n\n## Dividing the problem into subproblems\n\nI identified the following sub problems:\n\n1. this\n\n2. is\n\n3. a \n\n4. list\n\n### Subproblem 1\n\nLets get started writing some code:\n*)\n\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.16\u0022\n\nopen Plotly.NET\n\n/// some example data. see how this text is active when hovering over data in the post?\nlet data = [\n    0., 1.\n    1., 3.\n    2., 6.9\n    3., 1.337\n]\n\n(**\nHere is some rad visualization:\n*)\n\nlet myChart =\n    Chart.Spline(data)\n    |\u003E Chart.withTitle \u0022My first chart!\u0022\n \n(***hide***)\nmyChart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)"},{"uri":"/BIO-BTE-10-L-4/general/markdown_cheatsheet.html","title":"Markdown cheatsheet","content":"---\ntitle: Markdown cheatsheet\ncategory: general\ncategoryindex: 1\nindex: 2\n---\n\n# Markdown cheatsheet\n\n**Adapted from https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet**\n\nThis is intended as a quick reference and showcase. For more complete info, see [John Gruber\u0027s original spec](http://daringfireball.net/projects/markdown/) and the [Github-flavored Markdown info page](http://github.github.com/github-flavored-markdown/).\n\n### Table of Contents  \n\n- [Headers](#Headers)  \n- [Emphasis](#Emphasis)  \n- [Lists](#Lists)  \n- [Links](#Links)  \n- [Images](#Images)  \n- [Code and Syntax Highlighting](#Code-and-Syntax-Highlighting)  \n- [Tables](#Tables)\n- [Blockquotes](#Blockquotes)  \n- [Inline HTML](#Inline-HTML)  \n- [Horizontal Rule](#Horizontal-Rule)  \n- [Line Breaks](#Line-Breaks)  \n- [YouTube Videos](#YouTube-Videos)  \n\n## Headers\n\n\u0060\u0060\u0060no-highlight\n# H1\n## H2\n### H3\n#### H4\n##### H5\n###### H6\n\nAlternatively, for H1 and H2, an underline-ish style:\n\nAlt-H1\n======\n\nAlt-H2\n------\n\u0060\u0060\u0060\n\n# H1\n## H2\n### H3\n#### H4\n##### H5\n###### H6\n\nAlternatively, for H1 and H2, an underline-ish style:\n\nAlt-H1\n======\n\nAlt-H2\n------\n\n## Emphasis\n\n\u0060\u0060\u0060no-highlight\nEmphasis, aka italics, with *asterisks* or _underscores_.\n\nStrong emphasis, aka bold, with **asterisks** or __underscores__.\n\nCombined emphasis with **asterisks and _underscores_**.\n\nStrikethrough uses two tildes. ~~Scratch this.~~\n\u0060\u0060\u0060\n\nEmphasis, aka italics, with *asterisks* or _underscores_.\n\nStrong emphasis, aka bold, with **asterisks** or __underscores__.\n\nCombined emphasis with **asterisks and _underscores_**.\n\nStrikethrough uses two tildes. ~~Scratch this.~~\n\n## Lists\n\n(In this example, leading and trailing spaces are shown with with dots: \u22C5)\n\n\u0060\u0060\u0060no-highlight\n1. First ordered list item\n2. Another item\n\u22C5\u22C5* Unordered sub-list. \n1. Actual numbers don\u0027t matter, just that it\u0027s a number\n\u22C5\u22C51. Ordered sub-list\n4. And another item.\n\n\u22C5\u22C5\u22C5You can have properly indented paragraphs within list items. Notice the blank line above, and the leading spaces (at least one, but we\u0027ll use three here to also align the raw Markdown).\n\n\u22C5\u22C5\u22C5To have a line break without a paragraph, you will need to use two trailing spaces.\u22C5\u22C5\n\u22C5\u22C5\u22C5Note that this line is separate, but within the same paragraph.\u22C5\u22C5\n\u22C5\u22C5\u22C5(This is contrary to the typical GFM line break behaviour, where trailing spaces are not required.)\n\n* Unordered list can use asterisks\n- Or minuses\n\u002B Or pluses\n\u0060\u0060\u0060\n\n1. First ordered list item\n2. Another item\n  * Unordered sub-list. \n1. Actual numbers don\u0027t matter, just that it\u0027s a number\n  1. Ordered sub-list\n4. And another item.\n\n   You can have properly indented paragraphs within list items. Notice the blank line above, and the leading spaces (at least one, but we\u0027ll use three here to also align the raw Markdown).\n\n   To have a line break without a paragraph, you will need to use two trailing spaces.  \n   Note that this line is separate, but within the same paragraph.  \n   (This is contrary to the typical GFM line break behaviour, where trailing spaces are not required.)\n\n* Unordered list can use asterisks\n- Or minuses\n\u002B Or pluses\n\n## Links\n\nThere are two ways to create links.\n\n\u0060\u0060\u0060no-highlight\n[I\u0027m an inline-style link](https://www.google.com)\n\n[I\u0027m an inline-style link with title](https://www.google.com \u0022Google\u0027s Homepage\u0022)\n\n[I\u0027m a reference-style link][Arbitrary case-insensitive reference text]\n\n[I\u0027m a relative reference to a repository file](../blob/master/LICENSE)\n\n[You can use numbers for reference-style link definitions][1]\n\nOr leave it empty and use the [link text itself].\n\nURLs and URLs in angle brackets will automatically get turned into links. \nhttp://www.example.com or \u003Chttp://www.example.com\u003E and sometimes \nexample.com (but not on Github, for example).\n\nSome text to show that the reference links can follow later.\n\n[arbitrary case-insensitive reference text]: https://www.mozilla.org\n[1]: http://slashdot.org\n[link text itself]: http://www.reddit.com\n\u0060\u0060\u0060\n\n[I\u0027m an inline-style link](https://www.google.com)\n\n[I\u0027m an inline-style link with title](https://www.google.com \u0022Google\u0027s Homepage\u0022)\n\n[I\u0027m a reference-style link][Arbitrary case-insensitive reference text]\n\n[I\u0027m a relative reference to a repository file](../blob/master/LICENSE)\n\n[You can use numbers for reference-style link definitions][1]\n\nOr leave it empty and use the [link text itself].\n\nURLs and URLs in angle brackets will automatically get turned into links. \nhttp://www.example.com or \u003Chttp://www.example.com\u003E and sometimes \nexample.com (but not on Github, for example).\n\nSome text to show that the reference links can follow later.\n\n[arbitrary case-insensitive reference text]: https://www.mozilla.org\n[1]: http://slashdot.org\n[link text itself]: http://www.reddit.com\n\n## Images\n\n\u0060\u0060\u0060no-highlight\nHere\u0027s our logo (hover to see the title text):\n\nInline-style: \n![alt text](https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png \u0022Logo Title Text 1\u0022)\n\nReference-style: \n![alt text][logo]\n\n[logo]: https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png \u0022Logo Title Text 2\u0022\n\u0060\u0060\u0060\n\nHere\u0027s our logo (hover to see the title text):\n\nInline-style: \n![alt text](https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png \u0022Logo Title Text 1\u0022)\n\nReference-style: \n![alt text][logo]\n\n[logo]: https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png \u0022Logo Title Text 2\u0022\n\n## Code and Syntax Highlighting\n\nCode blocks are part of the Markdown spec, but syntax highlighting isn\u0027t. However, many renderers -- like Github\u0027s and *FSharp.Formatting* -- support syntax highlighting. Which languages are supported and how those language names should be written will vary from renderer to renderer. \n\n\u0060\u0060\u0060no-highlight\nInline \u0060code\u0060 has \u0060back-ticks around\u0060 it.\n\u0060\u0060\u0060\n\nInline \u0060code\u0060 has \u0060back-ticks around\u0060 it.\n\nBlocks of code are either fenced by lines with three back-ticks \u003Ccode\u003E\u0060\u0060\u0060\u003C/code\u003E, or are indented with four spaces. I recommend only using the fenced code blocks -- they\u0027re easier and only they support syntax highlighting.\n\nCurrently, only F# and C# syntax highlighting is supported by FSharp.Formatting. You can write code blocks in markdown like this\n\nF#:\n\n\u003Cpre\u003E\n\u003Ccode\u003E\u0060\u0060\u0060fsharp\u003C/code\u003E\nlet a = 42\n\u003Ccode\u003E\u0060\u0060\u0060\u003C/code\u003E\n\u003C/pre\u003E\n\n\u0060\u0060\u0060fsharp\nlet a = 42\n\u0060\u0060\u0060\n\nOr C#:\n\n\u003Cpre\u003E\n\u003Ccode\u003E\u0060\u0060\u0060csharp\u003C/code\u003E\nvar a = 42\n\u003Ccode\u003E\u0060\u0060\u0060\u003C/code\u003E\n\u003C/pre\u003E\n\n\u0060\u0060\u0060csharp\nvar a = 42\n\u0060\u0060\u0060\n\nFSharp.Formatting will also attempt to highlight snippets that are not in those languages, which will have mixed results\n\n\u003Cpre\u003E\n\u003Ccode\u003E\u0060\u0060\u0060javascript\u003C/code\u003E\nvar s = \u0022JavaScript syntax highlighting\u0022;\nalert(s);\n\u003Ccode\u003E\u0060\u0060\u0060\u003C/code\u003E\n\u003C/pre\u003E\n\n\n\u0060\u0060\u0060javascript\nconst a = 2\nvar s = \u0022JavaScript syntax highlighting? not really.\u0022;\nalert(s);\n// Some javascript keywords that are not detected because they are no equivalents in F#/C#:\nnative\nthrows\ninstanceof\n\u0060\u0060\u0060\n\nHowever, there is way better syntax highlighting and also tooltips available for F# and C# if you use script files for generating those docs instead. See an F# example [here](1_fsharp-code-example.html).\n\n## Tables\n\nTables aren\u0027t part of the core Markdown spec, but FSharp.Formatting supports them. Tables are styled via bulma striped table style.\n\n\u0060\u0060\u0060no-highlight\nColons can be used to align columns.\n\n| Tables        | Are           | Cool  |\n| ------------- |:-------------:| -----:|\n| col 3 is      | right-aligned | $1600 |\n| col 2 is      | centered      |   $12 |\n| zebra stripes | are neat      |    $1 |\n\nThere must be at least 3 dashes separating each header cell.\nThe outer pipes (|) are optional, and you don\u0027t need to make the \nraw Markdown line up prettily. You can also use inline Markdown.\n\nMarkdown | Less | Pretty\n--- | --- | ---\n*Still* | \u0060renders\u0060 | **nicely**\n1 | 2 | 3\n\u0060\u0060\u0060\n\nColons can be used to align columns.\n\n| Tables        | Are           | Cool |\n| ------------- |:-------------:| -----:|\n| col 3 is      | right-aligned | $1600 |\n| col 2 is      | centered      |   $12 |\n| zebra stripes | are neat      |    $1 |\n\nThere must be at least 3 dashes separating each header cell. The outer pipes (|) are optional, and you don\u0027t need to make the raw Markdown line up prettily. You can also use inline Markdown.\n\nMarkdown | Less | Pretty\n--- | --- | ---\n*Still* | \u0060renders\u0060 | **nicely**\n1 | 2 | 3\n\n## Blockquotes\n\n\u0060\u0060\u0060no-highlight\n\u003E Blockquotes are very handy in email to emulate reply text.\n\u003E This line is part of the same quote.\n\nQuote break.\n\n\u003E This is a very long line that will still be quoted properly when it wraps. Oh boy let\u0027s keep writing to make sure this is long enough to actually wrap for everyone. Oh, you can *put* **Markdown** into a blockquote. \n\u0060\u0060\u0060\n\n\u003E Blockquotes are very handy in email to emulate reply text.\n\u003E This line is part of the same quote.\n\nQuote break.\n\n\u003E This is a very long line that will still be quoted properly when it wraps. Oh boy let\u0027s keep writing to make sure this is long enough to actually wrap for everyone. Oh, you can *put* **Markdown** into a blockquote. \n\n## Inline HTML\n\nYou can also use raw HTML in your Markdown, and it\u0027ll mostly work pretty well. \n\n\u0060\u0060\u0060no-highlight\n\u003Cdl\u003E\n  \u003Cdt\u003EDefinition list\u003C/dt\u003E\n  \u003Cdd\u003EIs something people use sometimes.\u003C/dd\u003E\n\n  \u003Cdt\u003EMarkdown in HTML\u003C/dt\u003E\n  \u003Cdd\u003EDoes *not* work **very** well. Use HTML \u003Cem\u003Etags\u003C/em\u003E.\u003C/dd\u003E\n\u003C/dl\u003E\n\u0060\u0060\u0060\n\n\u003Cdl\u003E\n  \u003Cdt\u003EDefinition list\u003C/dt\u003E\n  \u003Cdd\u003EIs something people use sometimes.\u003C/dd\u003E\n\n  \u003Cdt\u003EMarkdown in HTML\u003C/dt\u003E\n  \u003Cdd\u003EDoes *not* work **very** well. Use HTML \u003Cem\u003Etags\u003C/em\u003E.\u003C/dd\u003E\n\u003C/dl\u003E\n\n## Horizontal Rule\n\n\u0060\u0060\u0060\nThree or more...\n\n---\n\nHyphens\n\n***\n\nAsterisks\n\n___\n\nUnderscores\n\u0060\u0060\u0060\n\nThree or more...\n\n---\n\nHyphens\n\n***\n\nAsterisks\n\n___\n\nUnderscores\n\n## Line Breaks\n\nMy basic recommendation for learning how line breaks work is to experiment and discover -- hit \u0026lt;Enter\u0026gt; once (i.e., insert one newline), then hit it twice (i.e., insert two newlines), see what happens. You\u0027ll soon learn to get what you want. \u0022Markdown Toggle\u0022 is your friend. \n\nHere are some things to try out:\n\n\u0060\u0060\u0060\nHere\u0027s a line for us to start with.\n\nThis line is separated from the one above by two newlines, so it will be a *separate paragraph*.\n\nThis line is also a separate paragraph, but...\nThis line is only separated by a single newline, so it\u0027s a separate line in the *same paragraph*.\n\u0060\u0060\u0060\n\nHere\u0027s a line for us to start with.\n\nThis line is separated from the one above by two newlines, so it will be a *separate paragraph*.\n\nThis line is also begins a separate paragraph, but...  \nThis line is only separated by a single newline, so it\u0027s a separate line in the *same paragraph*.\n\n## YouTube Videos\n\nThey can\u0027t be added directly but you can add an image with a link to the video like this:\n\n\u0060\u0060\u0060no-highlight\n\u003Ca href=\u0022http://www.youtube.com/watch?feature=player_embedded\u0026v=YOUTUBE_VIDEO_ID_HERE\n\u0022 target=\u0022_blank\u0022\u003E\u003Cimg src=\u0022http://img.youtube.com/vi/YOUTUBE_VIDEO_ID_HERE/0.jpg\u0022 \nalt=\u0022IMAGE ALT TEXT HERE\u0022 width=\u0022240\u0022 height=\u0022180\u0022 border=\u002210\u0022 /\u003E\u003C/a\u003E\n\u0060\u0060\u0060\n\nOr, in pure Markdown, but losing the image sizing and border:\n\n\u0060\u0060\u0060no-highlight\n[![IMAGE ALT TEXT HERE](http://img.youtube.com/vi/YOUTUBE_VIDEO_ID_HERE/0.jpg)](http://www.youtube.com/watch?v=YOUTUBE_VIDEO_ID_HERE)\n\u0060\u0060\u0060\n\n---\n\nLicense: [CC-BY](https://creativecommons.org/licenses/by/3.0/)"},{"uri":"/BIO-BTE-10-L-4/general/blog-post-guide.html","title":"Blog post guide","content":"(**\n---\ntitle: Blog post guide\ncategory: general\ncategoryindex: 1\nindex: 1\n---\n\n# Blog post guide\n\nThis is a guide on how to create content for the blog post that marks the final submission for your project work.\n\n**Table of contents**\n\n- [Setup](#setup)\n  - [Indepth info for the interested](#indepth-info-for-the-interested)\n    - [dotnet tools](#dotnet-tools)\n    - [fsdocs](#fsdocs)\n- [Creating content](#creating-content)\n  - [Markdown](#markdown)\n  - [Literate F# scripts](#literate-f-scripts)\n  - [Including output](#Including-output)\n  - [Including values](#Including-values)\n  - [rendering charts](#Rendering-charts)\n- [Submission guidelines](#submission-guidelines)\n  - [General content guidelines](#general-content-guidelines)\n  - [Submitting your blog post](#submitting-your-blog-post)\n\n_! This document is WIP. Please finish your project before writing the blog post to prevent usage of outdated information. !_\n\n## Setup\n\nAt this point you should have the [.NET SDK](https://dotnet.microsoft.com/download/dotnet/5.0) installed, as it is a mandatory installation. \nOtherwise we strongly recommend to consider first writing some code and getting into the project before reading to deep into how to create a blog post about your results.\n\nThat said, follow these steps to set up the blogpost project:\n\n1. Create a new folder for your blogpost\n2. Open a terminal (e.g. powershell/cmd on windows, bash on linux/macOS). Pro tip: Visual Studio Code has a built in terminal, which is very handy.\n3. Navigate to the new folder (type \u0060cd replace/this/text/with/path/to/your/folder\u0060)\n4. use the \u0060dotnet new tool-manifest\u0060 command to create a dotnet tool resgistry in the folder. This is basically a document that tracks what tools can be used in your project.\n5. Install the fslab template for fsdocs via \u0060dotnet new -i FsLab.DocumentationTemplate\u0060. You can learn more about this template [here](https://fslab.org/docs-template/)\n6. Initialize the template via \u0060dotnet new fslab-docs\u0060. When asked for permission to install the fsdocs tool, type \u0060y\u0060 to continue. \n7. Test the template via \u0060dotnet fsdocs watch --eval --clean\u0060. Here is what this means in a bit more detail:\n   - The \u0060dotnet\u0060 command prefix always means \u0022use the dotnet CLI(command line interface) to do the following:\u0022\n   - \u0060fsdocs\u0060 means you will use the \u0060fsdocs\u0060 tool\n   - \u0060watch\u0060 means that you will use \u0060fsdocs\u0060 in watch mode, an interactive mode where you will have the live output of your documents open in a local browser and can see the changes live.\n   - \u0060--eval\u0060 means that you want to evaluate (meaning execute) any F# script content. More on that later.\n   - \u0060--clean\u0060 means that you want to clean up any leftover stuff from the last run before starting.\n   - There may be a question for permission to start the local webserver. Allow it. You should now see this in your browser:\n    ![]()\n8. You have now set up an interactive blog post creation engine. changes to files in your folder will be reflected on the webpage that opened in your browser. \n9. To stop the tool, either press any button in the terminal you are running it, or interrupt the process by pressing \u0060ctrl \u002B c\u0060 in the terminal.\n\n### Indepth info for the interested\n\n#### dotnet tools\n\nComing soon\u003Csup\u003ETM\u003C/sup\u003E\n\n#### fsdocs\n\nComing soon\u003Csup\u003ETM\u003C/sup\u003E\n\n## Creating content\n\nIf you followed the setup steps, you have a folder set up to create content in. You can always preview your content by running \u0060dotnet fsdocs watch --eval --clean\u0060.\n\nContent for fsdocs can be created in two kinds of files: \u0060markdown\u0060 (\u0060.md\u0060) files and \u0060literate F# scripts\u0060. The core difference is that you can only write styled text in markdown, while you can add real code in literate F# scripts.\n\n### Markdown\n\nMarkdown is a set of easy to use formatting rules to create structured text. In fact, the very document you are reading is written in markdown.\n\nfor example, this is how to create a heading:\n\n\u0060\u0060\u0060\n# Hi, i am a large heading\n\u0060\u0060\u0060\n\nwill become:\n\n# Hi, i am a large heading\n\nYou may have realized that your initialized template contains a markdown cheatsheat. Use this cheatsheet for all your markdown needs. an online version is also available [here]({{root}}general/markdown_cheatsheet.html).\n\nYou might also have realized that the styling of your markdown looks different than this page (see the screenshot below for reference as well). \nThat is not a problem and depends on the styling that fsdocs uses. please use the default one that is coming with the template.\n\n![cheatsheet_screenshot](../img/markdown_cheatsheet.png)\n\n### Literate F# scripts\n\nLiterate F# scripts are a powerfull fusion of markdown with F# scripting and advanced formatting methods. \n\nWith literate F# scripts you can tell the full story from the problem to your solution and show of how it works and what kinds of results it produces.\n\nTo write markdown, just put it in these parentheses \u0060\u0060(** ... *)\u0060 like this: \u0060(** # i am a heading! *)\u0060. you can also do that across multiple lines.\n\n\u0060\u0060\u0060\n    (**\n    # Hi!\n    *markdown here :D*\n    *)\n\u0060\u0060\u0060\n\nBut the real awesome thing is that you can write normal F# code that will be rendered beautifully on your generated webpage.\n\nIt also contains hover tooltips! Try it by hovering over some of the code below with your mouse!\n*)\n\nlet a = 42\n\n///try hovering over myFunction!\nlet myFunction someParameter = printfn $\u0022i got some {someParameter}!\u0022\n\n(** \n\n### Including output\n\nthere are multiple ways of including output of function calls or values of bindings.\n\nTo include the output of a function that returns unit (so for example a \u0060printfn\u0060 call), put \u0060(***include-output***)\u0060 below the call:\n\n\u0060\u0060\u0060\n    printfn \u0022Hi\u0022\n    (***include-output***)\n\u0060\u0060\u0060\n\nwhich will be rendered as:\n*)\n\nprintfn \u0022Hi\u0022\n(***include-output***)\n\n(**\n\n### Including values\n\nTo include the value of a binding, use \u0060(***include-value: yourBindingname***)\u0060:\n\nso this:\n\n\u0060\u0060\u0060\n    let x = 42\n    (***include-value:x***)\n\u0060\u0060\u0060\n\nbecomes:\n\n*)\n\nlet x = 42\n(***include-value:x***)\n\n(**\n\n### Rendering charts\n\nChart rendering is a special value inclusion. Because Plotly.NET charts create html already, the raw string value of them (created by \u0060Chart.toChartHTML\u0060) has to be included via \u0060(***include-it-raw***)\u0060 like this: \n\n\u0060\u0060\u0060\n    #r \u0022nuget: Plotly.NET, 2.0.0-preview.16\u0022\n    open Plotly.NET\n\n    let myChart = Chart.Line([1,42; 2,69; 3,1337])\n\n    myChart\n    |\u003E GenericChart.toChartHTML\n    (***include-it-raw***) \n\u0060\u0060\u0060\n which will be rendered as:\n*)\n\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.16\u0022\nopen Plotly.NET\n\nlet myChart = Chart.Line([1,42; 2,69; 3,1337])\n\nmyChart\n|\u003E GenericChart.toChartHTML\n(***include-it-raw***) \n\n(** \nYou can also hide blocks via \u0060(***hide***)\u0060, a good use case is the inclusion of charts:\n\n\u0060\u0060\u0060\n    let myChart2 = Chart.Spline([1,42; 2,69; 3,1337])\n\n    (***hide***)\n    myChart2\n    |\u003E GenericChart.toChartHTML\n    (***include-it-raw***) \n\u0060\u0060\u0060\n\nwhich will omit the part of the code block that is only there to display the chart:\n*)\n\nlet myChart2 = Chart.Spline([1,42; 2,69; 3,1337])\n\n(***hide***)\nmyChart2\n|\u003E GenericChart.toChartHTML\n(***include-it-raw***) \n\n(**\n\n## Submission guidelines\n\n### General content guidelines\n\n### Submitting your blog post\n*)"},{"uri":"/BIO-BTE-10-L-4/projects/spectral-alignment.html","title":"Alignment of Peptide derived MS Spectra","content":"(**\n---\ntitle: Alignment of Peptide derived MS Spectra\ncategory: projects\ncategoryindex: 2\nindex: 3\n---\n*)\n\n(**\n# Alignment of Peptide derived MS Spectra.\n    \n**Interested?** Contact [muehlhaus@bio.uni-kl.de](mailto:muehlhaus@bio.uni-kl.de) or [d_zimmer@rhrk.uni-kl.de](mailto:d_zimmer@rhrk.uni-kl.de)\n\n#### Table of contents\n\n- [Introduction](#Introduction) \n- [Aim for this project](#Aim-for-this-project)\n- [Coding clues](#Coding-clues)\n- [References](#References)\n- [Additional information](#Additional-information)\n\n## Introduction\n\nModern Proteomics relies on the use of mass spectrometry (MS). Since it is not feasible to analyze proteins directly, MS-based shotgun proteomics estimates protein abundances using a proxy: peptides. \nWhile the whole process is complex enough to fill whole textbooks, this project focuses on a very specific puzzle piece: \n\n**The alignment of peptide derived MS spectra.** \n\nLet us motivate this problem by visual examination of the fragment spectra*\u0027* of two example peptides with the sequences \u0027PRTEIINNEE\u0027 (blue) and \u0027PRTEYINNEE\u0027 (orange).\n\n*\u0027*: For simplicity we will only consider b-ions at charge 1.\n*)\n\n(*** hide ***) \n#r \u0022nuget: FSharpAux, 1.1.0\u0022\n#r \u0022nuget: FSharpAux.IO, 1.1.0\u0022\n#r \u0022nuget: FSharp.Stats, 0.4.3\u0022 \n#r \u0022nuget: BioFSharp, 2.0.0-preview.1\u0022\n#r \u0022nuget: BioFSharp.Mz, 0.1.5-beta\u0022\n#r \u0022nuget: BioFSharp.IO, 2.0.0-beta6\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.16\u0022\nopen FSharpAux\nopen FSharpAux.IO\nopen BioFSharp\nopen BioFSharp.IO\nopen BioFSharp.Mz\nopen FSharp.Stats\nopen Plotly.NET\n\nlet PRTEIINNEE =   \n    \u0022PRTEIINNEE\u0022\n    |\u003E BioFSharp.BioList.ofAminoAcidString\n    |\u003E Fragmentation.Series.bOfBioList BioFSharp.BioItem.monoisoMass\n    |\u003E List.map (fun x -\u003E x.MainPeak.Mass,1.)\n\nlet PRTEYINNEE =   \n    \u0022PRTEYINNEE\u0022\n    |\u003E BioFSharp.BioList.ofAminoAcidString\n    |\u003E Fragmentation.Series.bOfBioList BioFSharp.BioItem.monoisoMass\n    |\u003E List.map (fun x -\u003E x.MainPeak.Mass,1.)\n\nlet specComp = \n    [\n        PRTEIINNEE \n        |\u003E Chart.Column\n        |\u003E Chart.withTraceName \u0022PRTEIINNEE\u0022\n        PRTEYINNEE \n        |\u003E Chart.Column\n        |\u003E Chart.withTraceName \u0022PRTEYINNEE\u0022\n    ]    \n    |\u003E Chart.combine\n    \nspecComp\n|\u003E GenericChart.toChartHTML\n(***include-it-raw***)    \n\n(**\nEven though that both peptides show very high sequence similarity and only differ by one amino acid, with \u0027I\u0027 at index 4 being substituted with \u0027Y\u0027, \nthis small change in the sequence results in a big change on the spectrum level. As one can see, more than half of all peaks do not overlap. This is problematic since many\nalgorithms that compare spectra aim to maximize matching peaks - This project is designed to tackle this gap by solving the **\u0027Spectral Alignment Problem\u0027.**\n\nBefore we formulate the problem and discover a strategy to tackle it we change the perspective: The following figure plots the peak positions of \nthe fragment spectra of the b-ions of \u0027PRTEIINNEE\u0027 versus the one of \u0027PRTEYINNEE\u0027. \nThe plot contains every possible pair of peaks (eg. the first peak of spectrum 1 and the second peak of spectrum 2) depicted as grey crosses.\nAdditionally, we added matching peaks as blue circles and non-matching peaks as orange triangles. You can see, that all matching peaks are placed\non the main diagonal (blue line), while the non-matching peaks are lined up at a constant offset, parallel to the main diagonal.\n*)\n\n(*** hide ***) \nlet vs = \n    let vs = \n        (List.zip (PRTEIINNEE |\u003E List.map fst) (PRTEYINNEE |\u003E List.map fst))\n    let matching = \n        vs |\u003E List.filter (fun (x,y) -\u003E x = y)\n    let nonMatching = \n        (vs |\u003E List.filter (fun (x,y) -\u003E x \u003C\u003E y))\n    let allPossibleMatchups = \n        let x,y = vs |\u003E List.unzip\n        [\n            for i = 0 to x.Length-1 do \n                for j = 0 to y.Length-1 do \n                    yield (x.[i],y.[j])\n        ]\n    [\n        Chart.Point(allPossibleMatchups)      \n        |\u003E Chart.withMarkerStyle(Size=5,Symbol=StyleParam.MarkerSymbol.Cross,Color=Color.fromKeyword Grey)\n        Chart.Point(matching)\n        |\u003E Chart.withMarkerStyle(Size=10,Symbol=StyleParam.MarkerSymbol.Circle,Color=Color.fromKeyword Blue)\n        Chart.Line([0.,0.;1400.,1400.])\n        |\u003E Chart.withMarkerStyle(Size=10,Symbol=StyleParam.MarkerSymbol.Circle,Color=Color.fromKeyword Blue)\n        Chart.Line(vs)\n        |\u003E Chart.withLineStyle(Dash=StyleParam.DrawingStyle.Dash,Color=Color.fromKeyword DarkGreen)      \n        Chart.Point(nonMatching)      \n        |\u003E Chart.withMarkerStyle(Size=10,Symbol=StyleParam.MarkerSymbol.TriangleUp,Color=Color.fromKeyword Orange)\n    ]    \n    |\u003E Chart.combine\n    |\u003E Chart.withYAxisStyle(\u0022PRTEIINNEE\u0022,MinMax=(1250.,0.))\n    |\u003E Chart.withXAxisStyle(\u0022PRTEYINNEE\u0022,MinMax=(0.,1250.))\n    |\u003E Chart.withLegend false\n\n    \nvs\n|\u003E GenericChart.toChartHTML\n(***include-it-raw***)      \n\n\n(**\nThe pattern which we want to highlight here becomes even more evident if we raise the amount of amino acid mutations by one and plotting the b-ion spectrum of \u0027PRTEIINNEE\u0027 versus the one of \u0027PRTEYINYEE\u0027. \n*)\n\n(*** hide ***) \nlet PRTEYINYEE =   \n    \u0022PRTEYINYEE\u0022\n    |\u003E BioFSharp.BioList.ofAminoAcidString\n    |\u003E Fragmentation.Series.bOfBioList BioFSharp.BioItem.monoisoMass\n    |\u003E List.map (fun x -\u003E x.MainPeak.Mass,1.)\n\nlet vs2 = \n    let vs = \n        (List.zip (PRTEIINNEE |\u003E List.map fst) (PRTEYINYEE |\u003E List.map fst))\n    let matching = \n        [0.,0.]@(vs |\u003E List.filter (fun (x,y) -\u003E x = y))\n    let nonMatching = \n        (vs |\u003E List.filter (fun (x,y) -\u003E x \u003C\u003E y))\n    let allPossibleMatchups = \n        let x,y = vs |\u003E List.unzip\n        [\n            for i = 0 to x.Length-1 do \n                for j = 0 to y.Length-1 do \n                    yield (x.[i],y.[j])\n        ]\n    [\n        Chart.Point(allPossibleMatchups)      \n        |\u003E Chart.withMarkerStyle(Size=5,Symbol=StyleParam.MarkerSymbol.Cross,Color=Color.fromKeyword Grey)\n        Chart.Point(matching)\n        |\u003E Chart.withMarkerStyle(Size=10,Symbol=StyleParam.MarkerSymbol.Circle,Color=Color.fromKeyword Blue)\n        Chart.Line([0.,0.;1400.,1400.])\n        |\u003E Chart.withMarkerStyle(Size=10,Symbol=StyleParam.MarkerSymbol.Circle,Color=Color.fromKeyword Blue)\n        Chart.Line(vs)\n        |\u003E Chart.withLineStyle(Dash=StyleParam.DrawingStyle.Dash,Color=Color.fromKeyword DarkGreen)      \n        Chart.Point(nonMatching)      \n        |\u003E Chart.withMarkerStyle(Size=10,Symbol=StyleParam.MarkerSymbol.TriangleUp,Color=Color.fromKeyword Orange)\n    ]    \n    |\u003E Chart.combine\n    |\u003E Chart.withYAxisStyle(\u0022PRTEIINNEE\u0022,MinMax=(1350.,0.))\n    |\u003E Chart.withXAxisStyle(\u0022PRTEYINYEE\u0022,MinMax=(0.,1350.))\n    |\u003E Chart.withLegend false\n\n    \nvs2\n|\u003E GenericChart.toChartHTML\n(***include-it-raw***) \n\n(**\nAs one can see, the addition of another mutation has the effect that the 6 non-matching peaks are now lined up at 2 distinct offsets, resulting in three peaks per offset which are placed parallel to the main diagonal. Analyzing the plot carefully, you can derive that the green path is the **longest path** one can find with at most k=2 shifts from the main diagonal.\nIn practice this information can be used to identify spectra that are the result of modified or mutated peptides: Your main task will be to solve the following **longest path** problem and to provide an\nefficient implementation: \n\n\u003E **Spectral Alignment Problem:**\n\u003E Description: Find the k-similarity between two Spectra.\n\u003E\n\u003E Input: Spectrum $Sa$ , Spectrum $Sb$, number of shifts $k$  \n\u003E\n\u003E Output: The $k$ -similarity, $D(k)$, between $Sa$ and $Sb$ \n\u003E\n*)\n\n(**\n## Aim for this project\n\nThis project is your chance to dive into a topic of great relevance to modern biology: MS-based shotgun proteomics. \n\n- **By completing this assignment you will understand the basic principles of modern proteomics and gain a deep understanding of peptide identification.** \n\n- **Finally, you will implement an efficient version of spectral alignment to extend the BioFSharp.Mz library.**\n\n*)\n(**\n## Coding clues\n*)\n(**\nFortunately, you can straight away start your journey since many functionalities are already implemented in the BioFSharp and BioFSharp.Mz libaries. The following snippet creates a function that returns\na fragment spectrum consisting of b-ions at intensity 1 based on a string encoded peptide sequence: \n*)\n\nlet calcBIonFragments pepSequence =   \n    pepSequence\n    |\u003E BioFSharp.BioList.ofAminoAcidString\n    |\u003E Fragmentation.Series.bOfBioList BioFSharp.BioItem.monoisoMass\n    |\u003E List.map (fun x -\u003E x.MainPeak.Mass,1.)\n\n(**\nThis function can for example be used to recreate the first sample from above:\n*)\n\nlet PRTEIINNEE\u0027 =   \n    \u0022PRTEIINNEE\u0022\n    |\u003E calcBIonFragments\nlet PRTEYINNEE\u0027 =   \n    \u0022PRTEYINNEE\u0022\n    |\u003E calcBIonFragments\n\nlet specComp\u0027 = \n    [\n        PRTEIINNEE\u0027 \n        |\u003E Chart.Column\n        |\u003E Chart.withTraceName \u0022PRTEIINNEE\u0022\n        PRTEYINNEE\u0027 \n        |\u003E Chart.Column\n        |\u003E Chart.withTraceName \u0022PRTEYINNEE\u0022\n    ]    \n    |\u003E Chart.combine\n    \nspecComp\u0027\n|\u003E GenericChart.toChartHTML\n\n(**\nTo allow you a little head start we provide you with a **very naive** implementation of the spectral alignment problem*\u0027\u0027*. \n\n**Disclaimer: You can use this implementation to benchmark against, or just familiarize yourself with the problem. You are by no means obligated to use this implementation as a blue print!**\n\nIn contrast to this naive implementation, the algorithm provided by you should be more efficient as well as applicable on mass spectra which consist of b and y ions*\u0027\u0027* at charges up to 4.\nAdditionally, this naive implementation assumes that masses are measured as integers. Your algorithm should be able to take floating point values as an input.\n\n*\u0027\u0027*: Remember in the examples above we only considered b-ions at charge 1. \n*)\n\ntype Path = {\n    K         : int\n    PathIndices: list\u003Cint*int\u003E\n    }\n   \n// \nlet findAllPaths maxK (m:Matrix\u003Cfloat\u003E) = \n    let extendInAllPossibleDirections (m:Matrix\u003Cfloat\u003E) maxK currentRow (path :Path) = \n        if path.K \u003E= maxK then \n            let lastRow,lastCol = path.PathIndices.Head\n            let colinearCol = currentRow-lastRow\u002BlastCol\n            if colinearCol \u003E m.NumCols-1 then \n                [path]\n            else\n            let acc\u0027 =\n                let v = m.[currentRow,colinearCol]\n                if v = 1. then \n                    (currentRow,colinearCol)::path.PathIndices\n                else\n                    path.PathIndices \n            [{path with PathIndices = acc\u0027}]\n        else \n            let newV =\n                let _,lastCol = path.PathIndices.Head \n                [\n                    for j = (lastCol \u002B 1) to m.NumCols-1 do\n                        let v = m.[currentRow,j]\n                        if v = 1. then yield (currentRow,j) \n                ]\n            match newV with \n            | [] -\u003E [path]\n            | _ -\u003E \n            let newPaths = \n                newV\n                |\u003E List.map (fun (currentRow,matchingColumn) -\u003E (currentRow,matchingColumn)::path.PathIndices)\n                |\u003E List.map (fun acc\u0027 -\u003E\n                    let k\u0027 = \n                        match acc\u0027 with \n                        | [] -\u003E path.K\n                        | x::[] -\u003E path.K\n                        | x::y::t -\u003E \n                            if (fst x - fst y) = (snd x - snd y) then \n                                path.K\n                            else path.K \u002B 1\n                    {K=k\u0027;PathIndices=acc\u0027}\n                    )\n            path::newPaths\n    let rec loop paths currentRowIdx =\n        if currentRowIdx \u003E m.NumRows-1 then \n            paths\n        else\n            let expandedPaths = \n                paths\n                |\u003E List.collect (extendInAllPossibleDirections m maxK currentRowIdx)           \n            loop expandedPaths (currentRowIdx\u002B1)\n    loop [{K=0;PathIndices=[0,0]}] 0\n\n//\nlet calcSimilarityAt_simple k (specA:int[]) (specB:int[]) =\n    let n :int = System.Math.Max(specA |\u003E Array.max,specB |\u003E Array.max)\n    let vecA = \n        let tmp = FSharp.Stats.Vector.create (n\u002B1) 0.\n        specA\n        |\u003E Array.iter (fun p -\u003E tmp.[p] \u003C- 1.)\n        tmp\n    let vecB = \n        let tmp = FSharp.Stats.Vector.create (n\u002B1) 0.\n        specB\n        |\u003E Array.iter (fun p -\u003E tmp.[p] \u003C- 1.)\n        tmp\n    let m = vecA * vecB.Transpose\n    let longestPath = \n        findAllPaths k m\n        |\u003E List.maxBy (fun p -\u003E p.PathIndices.Length)\n    longestPath.PathIndices.Length - 1\n\n\n(**\nUsing this implementation we encourage you to read the paper \u0022Mutation-Tolerant Protein Identification by Mass Spectrometry\u0022 (see References), \nwhich takes a deep dive into the topic. In the following code snippet we will apply our naive implementation to examples from the paper - something we also \nadvise you to do - once you come up with your first implementation. \n*)\n// Example 1\nlet sa = [|10; 20; 30; 40; 50; 60; 70; 80; 90; 100|]\nlet sb = [|10; 20; 30; 40; 50; 55; 65; 75; 85; 95|]\nlet sc = [|10; 15; 30; 35; 50; 55; 70; 75; 90; 95|]\n\n// should be 10\nlet D_1_sa_sb =  calcSimilarityAt_simple 1 sa sb  \n\n// should be 6\nlet D_1_sa_sc =  calcSimilarityAt_simple 1 sa sc  \n\n\n// Example 2\nlet sd = [|7; 11; 15; 18; 21; 24; 30; 38; 43|]\nlet se = [|7; 11; 13; 19; 22; 25; 31; 33; 38|]\n\n// the authors claim its 5.\nlet D_1_sd_se =  calcSimilarityAt_simple 1 sd se  \n\n// should be 8\nlet D_2_sd_se =  calcSimilarityAt_simple 2 sd se  \n\n(**\n## References\n\nMutation-Tolerant Protein Identification by Mass Spectrometry, P. A. Pevzner et al. 2000\n\nEfficiency of Database Search for Identification of Mutated and Modified Proteins via Mass Spectrometry, P. A. Pevzner et al. 2001\n\n*)\n\n(**\n## Additional information\n\n- We strongly advise to work through the paper \u0022Mutation-Tolerant Protein Identification by Mass Spectrometry\u0022. It \nserves as a very good introduction into the topic and gives you many ideas on how to write an efficient implementation.\n\n*)"},{"uri":"/BIO-BTE-10-L-4/projects/tSNE.html","title":"t-Distributed Stochastic Neighbour Embedding","content":"(**\n---\ntitle: t-Distributed Stochastic Neighbour Embedding\ncategory: projects\ncategoryindex: 2\nindex: 1\n---\n*)\n\n\n(**\n# t-Distributed Stochastic Neighbour Embedding (tSNE)\n\n**Interested?** Contact [muehlhaus@bio.uni-kl.de](mailto:muehlhaus@bio.uni-kl.de) or [venn@bio.uni-kl.de](mailto:venn@bio.uni-kl.de)\n\n#### Table of contents\n\n- [Introduction](#Introduction) \n- [Aim for this project](#Aim-for-this-project)\n- [Coding clues](#Coding-clues)\n    - [Notes](#Notes)\n    - [Pseudocode](#Pseudocode)\n    - [Step 0](#0-sup-th-sup-step)\n    - [Step 1](#1-sup-st-sup-step)\n    - [Step 2](#2-sup-nd-sup-step)\n    - [Step 3](#3-sup-rd-sup-step)\n    - [Step 4](#4-sup-th-sup-step)\n    - [Step 5](#5-sup-th-sup-step)\n    - [Step 6](#6-sup-th-sup-step)\n    - [Step 7](#7-sup-th-sup-step)\n    - [Step 8 - Function implementation in F#](#8-sup-th-sup-step-Function-implementation-in-F)\n- [References](#References)\n- [Additional information](#Additional-information)\n    - [Testing](#Testing)\n    - [Blog post](#Blog-post)\n\n## Introduction\n\n  - tSNE is a dimensionality reduction method. It allows you to visualise a multi-dimensional dataset in 2 or 3 dimensional scatter plot. \nBut what does that mean in practice? Imagine you measured height, weight, width, density, brightness, as well as magnetic, chemical, \nand physical properties of a bunch of objects. The simplest technique to summarize your measurements is a spreadsheet table in which each \nrow represents an element, and each column represents a measured feature:\n\n\n  |Object ID|height|weight|width|density|brightness|magnetic field|...|\n  |---------|------|------|-----|-------|----------|--------------|---|\n  |objectA|2|30|3|2|200|100000|...|\n  |objectB|4|50|2|3|255|130000|...|\n  |objectC|15|20|1|2|11|10000000|...|\n  |...|...|...|...|...|...|...|...|\n  \n\n  - Note that the measured features span multiple orders of magnitude. A change of 1 in height for example has much more value than a change \nof 1 regarding the magnetic field. If now clusters of similar behaving objects should be identified, you are limited to inspect the data set \ncolumn-wise by repetitive sorting. Just from the table you cannot create a meaningful graph, that allows you to perform a visual inspection of all features at once. \nLike principal component analysis (PCA), tSNE is a method for dimensionality reduction. It aggregates all features to a feature subset that \nallows a visual inspection of the complex data. It often is applied in image processing, NLP, genomic data, and speech processing. \n  \n  \n  ![](../img/tSNE.png)\n  Fig. 1: Idea of tSNE. Visualisation of a high dimensional data on a 2-dimensional scatter plot. \n  \n## Aim for this project\n\n1. Blog post introducing the method, its applications, and limitations.\n\n2. Implement t-Distributed Stochastic Neighbour Embedding in FSharp.Stats.\n\n  \n## Coding clues\n\n### Notes:\n\n  - All functions below are taken from the original publication (van der Maaten and Hinton 2008).\n\n  - Be aware, that the original work first describes SNE and later (section 3) describes the differences made to result in t-SNE!\n\n  - Although variance is continually referred to as \u03C3\u003Csub\u003Ei\u003C/sub\u003E in the paper, that is a repeated typo and should be \u03C3\u003Csub\u003Ei\u003C/sub\u003E\u003Csup\u003E2\u003C/sup\u003E.\n\n  - The data matrix has n rows (without header row). The first index defines the row, the second the column!\n\n  - x\u003Csub\u003Ei\u003C/sub\u003E defines the i\u003Csup\u003Eth\u003C/sup\u003E row in the data matrix (a vector of measured features).\n\n  - ||x|| indicates the vector norm, in this case it is the Euclidean distance between vector x\u003Csub\u003Ei\u003C/sub\u003E and y\u003Csub\u003Ei\u003C/sub\u003E. You can find distance metrics at \u0060\u0060\u0060FSharp.Stats.ML.DistanceMetrics\u0060\u0060\u0060.\n\n  - exp(t) indicates e\u003Csup\u003Et\u003C/sup\u003E\n\n  - A t distribution with degree of freedom = 1 is equal to 0.3183*(1\u002Bt\u00B2)-1 where the first constant part can be neglected if the constant term exists in all calculations.\n\n### Pseudocode:\n\n![](../img/tSNE_pc.png)\n\n#### 0\u003Csup\u003Eth\u003C/sup\u003E step: \n\n  - Read the publication and visit further introduction material you can find below (References)\n  \n#### 1\u003Csup\u003Est\u003C/sup\u003E step: \n\n  - create a F# script (.fsx), load and open \u0060\u0060\u0060FSharp.Stats\u0060\u0060\u0060, \u0060\u0060\u0060FSharpAux\u0060\u0060\u0060, and \u0060\u0060\u0060Plotly.NET\u0060\u0060\u0060\n\n  - import test data\n\n    - You can find the classic clustering dataset \u0022iris\u0022 [here](https://github.com/fslaborg/FSharp.Stats/tree/developer/docs/data).\n\n*)\n\n(******)\n\n#r \u0022nuget: FSharp.Stats, 0.4.1\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-beta9\u0022\n            \nopen FSharp.Stats\nopen Plotly.NET\n\n\nlet fromFileWithSep (separator:char) (filePath) =     \n    // The function is implemented using a sequence expression\n    seq {   let sr = System.IO.File.OpenText(filePath)\n            while not sr.EndOfStream do \n                let line = sr.ReadLine() \n                let words = line.Split separator//[|\u0027,\u0027;\u0027 \u0027;\u0027\\t\u0027|] \n                yield words }\n\n                \nlet lables,data =\n    fromFileWithSep \u0027,\u0027 (__SOURCE_DIRECTORY__ \u002B \u0022../content/irisData.csv\u0022)\n    |\u003E Seq.skip 1\n    |\u003E Seq.map (fun arr -\u003E arr.[4], [| float arr.[0]; float arr.[1]; float arr.[2]; float arr.[3]; |])\n    |\u003E Seq.toArray\n    |\u003E Array.shuffleFisherYates\n    |\u003E Array.mapi (fun i (lable,data) -\u003E sprintf \u0022%s_%i\u0022 lable i, data)\n    |\u003E Array.unzip\n\n\n(**\n\n#### 2\u003Csup\u003End\u003C/sup\u003E step:\n\n  - Calculate a Euclidean distance matrix using \u0060\u0060\u0060ML.DistanceMetrics.euclidean\u0060\u0060\u0060. The matrix\u2019 dimensions are n x n.\n  \n  - Define functions that calculate similarity measures using the prior defined distance matrix:\n    \n    - (1) high dimensional affinity p (p\u003Csub\u003Ei|j\u003C/sub\u003E)(Equation 1)\n\n      - Inform yourself how the variance is determined. If required define a Perplexity beforehand.\n\n    - (2) low dimensional affinity q (q\u003Csub\u003Eij\u003C/sub\u003E) (Equation 4)\n\n\n#### 3\u003Csup\u003Erd\u003C/sup\u003E step: \n\n  - Calculate the high dimensional affinity matrix between every data pair.\n\n    - Note: p\u003Csub\u003Eij\u003C/sub\u003E \u2260 p\u003Csub\u003Ei|j\u003C/sub\u003E\n\n    - p\u003Csub\u003Eij\u003C/sub\u003E = (p\u003Csub\u003Ej|i\u003C/sub\u003E \u002B p\u003Csub\u003Ei|j\u003C/sub\u003E) / 2n\n\n  - The matrix has the dimensions n x n . The similarity of a point to itself is 0.\n\n\n#### 4\u003Csup\u003Eth\u003C/sup\u003E step: \n\n  - Create an initial solution y(0) so that:\n\n    - y(0) is a matrix (n x d)\n\n    - y(0) contains as many rows as the original data matrix has rows (n)\n\n    - The number of values in each row is the number of dimensions you want to obtain in the end (d; in most cases 1-3, but should be defined by user).\n\n    - Each value is a randomly sampled from a normal distribution with mean = 0 and var = 0.0001.\n\n*)\n\n(******)\n\n// defines a normal distribuiton with mean = 3 and stDev = 2\nlet normalDist = Distributions.Continuous.normal 3. 2.\n\nlet createInitialGuess n = Array.init n (fun x -\u003E normalDist.Sample())\n\n// see FSharp.Stats documentation for probability distributions in the first code block for details\n// https://fslab.org/FSharp.Stats/Distributions.html#Normal-distribution)\n\n\n(**\n\n\n#### 5\u003Csup\u003Eth\u003C/sup\u003E step:\n\n  - Recursively loop from t=1 to T (number of iterations)\n\n\n  - calculate low dimensional affinities (q\u003Csub\u003Eij\u003C/sub\u003E (Equation 4)) for all low dimensional result vectors from 3\u003Csup\u003Erd\u003C/sup\u003E step. Collect results in a matrix (n x n).\n\n  - compute gradient (Equation 5)\n\n  - calculate the updated result y(t) and repeat.\n\n#### 6\u003Csup\u003Eth\u003C/sup\u003E step:\n\n  - report y(T) as final result\n\n#### 7\u003Csup\u003Eth\u003C/sup\u003E step:\n  \n  - Use a 2D and 3D scatter plot from Plotly.NET to visualize your result.\n\n#### 8\u003Csup\u003Eth\u003C/sup\u003E step: Function implementation in F#\n\n  - create a function, that contains all necessary helper functions in its body and takes the following parameters (suggestion):\n  \n  |Parameter name|data type|description|\n  |--------------|---------|-----------|\n  |data|\u0060\u0060\u0060matrix\u0060\u0060\u0060|datamatrix (cols=features, rows=elements)|\n  |dimensions|\u0060\u0060\u0060int\u0060\u0060\u0060|number of dimensions the final output data points have|\n  |maxIter|\u0060\u0060\u0060int\u0060\u0060\u0060|maximal number of iterations|\n  |perplexity|\u0060\u0060\u0060float\u0060\u0060\u0060|inform yourself if the perplexity should be defined by the user, or is calculated within the algorithm|\n  |learnRate|\u0060\u0060\u0060float\u0060\u0060\u0060|inform yourself|\n  |momentum|\u0060\u0060\u0060float\u0060\u0060\u0060|inform yourself|\n\n  - Default parameters should be given in the function description or as optional paramter.\n\n\n## References\n\n  - van der Maaten \u0026 Hinton; Visualizing Data using t-SNE (2008) [PDF](https://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf )\n\n  - https://www.youtube.com/watch?v=NEaUSP4YerM \n\n  - https://cran.r-project.org/web/packages/Rtsne/Rtsne.pdf page 5\n\n  - https://www.analyticsvidhya.com/blog/2017/01/t-sne-implementation-r-python/\n\n    - Note: Inform yourself if the variance in Step 4 is in fact based on t distribution or if at this point of the algorithm a standard gaussian normal distribution is used!\n\n  - https://www.datacamp.com/community/tutorials/introduction-t-sne\n\n\n## Additional information\n\n### Testing\n\n  - Apply tSNE to a dataset of your choice.\n\n  - optional: Test your results against implementations in R/Python or in the best case against the datasets proposed in the original publication.\n\n### Blog post \n\n  - Don\u2019t forget to describe the limits/weaknesses of the approach in your blog post.\n\n  - How to handle/preprocess ties?\n\n  - optional: Compare the method to PCA.\n\n*)\n\n"},{"uri":"/BIO-BTE-10-L-4/projects/hClust.html","title":"Efficient agglomerative hierarchical clustering","content":"(**\n---\ntitle: Efficient agglomerative hierarchical clustering\ncategory: projects\ncategoryindex: 2\nindex: 2\n---\n*)\n\n(**\n# Implementation of an efficient hierarchical agglomerative clustering algorithm\n\n**Interested?** Contact [muehlhaus@bio.uni-kl.de](mailto:muehlhaus@bio.uni-kl.de) or [venn@bio.uni-kl.de](mailto:venn@bio.uni-kl.de)\n\n#### Table of contents\n\n- [Introduction](#Introduction) \n- [Aim for this project](#Aim-for-this-project)\n- [Coding clues](#Coding-clues)\n    - [Step 0](#0-sup-th-sup-step)\n    - [Step 1](#1-sup-st-sup-step)\n    - [Step 2 - generate priority queue](#2-sup-nd-sup-step-Generate-priority-queue)\n    - [Step 3](#3-sup-rd-sup-step)\n    - [Step 4](#4-sup-th-sup-step)\n    - [Step 5](#5-sup-th-sup-step)\n    - [Step 6 - Function implementation in F#](#6-sup-th-sup-step-Function-implementation-in-F)\n    - [Step 7 - Further coding considerations](#7-sup-th-sup-step-Further-coding-considerations)\n- [References](#References)\n- [Additional information](#Additional-information)\n    - [Testing](#Testing)\n    - [Blog post](#Blog-post)\n\n\n## Introduction\n\n![](../img/overview.png)\n\nFig 1: Generating a hierarchical tree structure from a complex data set. Vertical thresholds (yellow, green, violet) generate different cluster numbers.\n\nClustering methods can be used to group elements of a huge data set based on their similarity. Elements sharing similar properties cluster together and can be \nreported as coherent group. These properties could be e.g. (a) similar gene expression kinetics in time series, (b) similar physicochemical properties, (c) genetic \nsimilarity measures for phylogenetic trees, etc.\n\nMany clustering algorithms require a predefined cluster number, that has to be provided by the experimenter. The most common approach is _k_-means clustering, \nwhere _k_ stands for the user defined cluster number. This kind of user interaction can lead to results, that are not objective, but highly influenced by the \nview and expectation of the experimenter. \n\nHierarchical clustering (_hClust_) does not require such cluster number definition. Instead, _hClust_ reports all possible cluster numbers \n(One big cluster with all elements to n clusters where every element is a singleton in its own cluster) in a tree structure (Fig 1). \nA _hClust_ tree has a single cluster (node) on its root and recursively splits up into clusters of elements that are more similar to each other than \nto elements of other clusters. For generating multiple cluster results with different number of clusters, the clustering has to performed only once. \nSubsequently the tree can be cut at any vertical line which will result in a defined number of clusters.\n\nThere are two types of _hClust_: \n\n  - Agglomerative (bottom-up): Each data point is in its own cluster and the nearest ones are merged recursively. It is referred to agglomerative hierarchical clustering (_HAC_)\n\n  - Divisive (top-down): All data points are in the same cluster and you divide the cluster into two that are far away from each other.\n\n  - The presented implementation is an agglomerative type.\n\n\nThere are several distance metrics, that can be used as distance function. The commonly used one probably is Euclidean distance. By inverting the distance, you end up with a similarity. High similarities indicate low distances, and vice versa. By calculating the similarities for every element pair, a similarity matrix can be generated.\n\n![](../img/simMatrix.png)\n\nFig 2: Data matrix (left) with measurement types as columns and (biological) entities as rows. The data matrix can be converted into a similarity matrix, that contain the inverse of distances.\n\n![](../img/workflow.png)\n\nFig 3: Workflow as proposed in pseudo code in Reference#2. \n\n\n## Aim for this project\n\n1. Blog post introducing the method, its applications, and limitations.\n\n2. Implement an efficient agglomerative hierarchical clustering in FSharp.Stats.\n\n\n## Coding clues\n\n### 0\u003Csup\u003Eth\u003C/sup\u003E step: \n\n  - Inform yourself about \n\n    - queues and priority queues (roughly)\n\n    - similarity measurements such as Euclidean distance, Manhattan distance, the advantage to use the squared Euclidean distance\n\n    - single linkage, complete linkage, and centroid based linkage types\n\n  - Down below you can see the pseudo code (not F#!) the efficient agglomerative hierarchical clustering (_HAC_) is based on:\n\n    \u0060\u0060\u0060\n    // Generating priority queue\n    Q = [] //priority queue \n    for n = 1 to N \n        for i = 1 to N \n            Q.enqueue(SIM(d[i], d[n]), (i, n)) \n    \n    // iterative agglomerative clustering\n    for k = 1 to N-1 \n        \u003Ci,m\u003E = Q.dequeue() \n        mergedCluster = merge((i,m)) \n    \n        Q.remove((_,m)) //remove any similarity that includes m \n    \n        for j = 1 to N \n            Q.update((i,j), SIM(mergedCluster, d[j])) \n    \u0060\u0060\u0060\n\n\n### 1\u003Csup\u003Est\u003C/sup\u003E step: \n\n  - create a F# script (.fsx), load and open \u0060\u0060\u0060FSharp.Stats\u0060\u0060\u0060, \u0060\u0060\u0060FSharpAux\u0060\u0060\u0060 and \u0060\u0060\u0060FSharpx.Collections\u0060\u0060\u0060\n\n  - import test data\n\n    - You can find the classic clustering dataset \u0022iris\u0022 [here](https://github.com/fslaborg/FSharp.Stats/tree/developer/docs/data).\n\n  - An implementation of an priority queue is given below.\n    \n  - _Please read this project description carefully before starting the implementation steps. A modification given in [Reference#2](https://github.com/srirambaskaran/efficient-hierarchical-clustering). \n  that boosts the efficiancy is not covered by the steps below. See the \u00227: Further coding considerations\u0022 in the end!_\n\n\n*)\n\n(******)\n\n#r \u0022nuget: FSharpAux, 1.1.0\u0022\n#r \u0022nuget: FSharp.Stats, 0.4.3\u0022\n#r \u0022nuget: FSharpx.Collections, 2.1.3\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.16\u0022\n            \nopen FSharp.Stats\nopen FSharpAux\nopen FSharpx.Collections\nopen Plotly.NET\n\n                \nlet lables,data =\n    let fromFileWithSep (separator:char) (filePath) =     \n        // The function is implemented using a sequence expression\n        seq {   let sr = System.IO.File.OpenText(filePath)\n                while not sr.EndOfStream do \n                    let line = sr.ReadLine() \n                    let words = line.Split separator//[|\u0027,\u0027;\u0027 \u0027;\u0027\\t\u0027|] \n                    yield words }\n    fromFileWithSep \u0027,\u0027 (__SOURCE_DIRECTORY__ \u002B \u0022../content/irisData.csv\u0022)\n    |\u003E Seq.skip 1\n    |\u003E Seq.map (fun arr -\u003E arr.[4], [| float arr.[0]; float arr.[1]; float arr.[2]; float arr.[3]; |])\n    |\u003E Seq.toArray\n    |\u003E FSharp.Stats.Array.shuffleFisherYates\n    |\u003E Array.mapi (fun i (lable,data) -\u003E sprintf \u0022%s_%i\u0022 lable i, data)\n    |\u003E Array.unzip\n\n    \ntype PriorityQueue\u003C\u0027T when \u0027T : comparison\u003E(values : \u0027T [], comparisonF : \u0027T -\u003E float) = \n        \n    let sort = Array.sortByDescending comparisonF\n    let mutable data = sort values \n    \n    new (comparisonF) = PriorityQueue(Array.empty,comparisonF)\n    \n    interface System.Collections.IEnumerable with\n        member this.GetEnumerator() = data.GetEnumerator()\n    \n    member this.UpdateElement (t:\u0027T) (newt:\u0027T) =     \n        let updated =\n            data \n            |\u003E Array.map (fun x -\u003E if x = t then newt else x)\n            |\u003E sort\n        data \u003C- updated\n          \n    member this.Elements = data\n        \n    member this.RemoveElement (t:\u0027T) = \n        let filtered = \n            Array.filter (fun x -\u003E x \u003C\u003E t) data\n        data \u003C- filtered\n    \n    member this.GetHead :\u0027T = \n        Array.head data\n    \n    member this.Dequeue() = \n        let head,tail = Array.head data, Array.tail data\n        data \u003C- tail\n        head, this\n    \n    member this.Insert (t:\u0027T) = \n        let newd = Array.append data [|t|] |\u003E sort\n        data \u003C- newd\n\n    member this.UpdateBy (updateElementFunction: \u0027T -\u003E \u0027T) = \n        let newd = \n            Array.map updateElementFunction data \n            |\u003E sort\n        data \u003C- newd\n\n    member this.RemoveElementsBy (predicate: \u0027T -\u003E bool) = \n        let newd = \n            Array.filter predicate data \n        data \u003C- newd\n\n(**\n### 2\u003Csup\u003End\u003C/sup\u003E step: Generate priority queue\n\n  - For each data point calculate the distances to each of the other points. \n\n    - You can find different kinds of distance measures in \u0060\u0060\u0060ML.DistanceMetrics\u0060\u0060\u0060\n\n    - Similarity can be interpreted as inverse distance. The lower the distance, the higher the similarity and the faster the data points have to be merged. \n    An appropriate type to store the result could be the following:\n\n*)\n\n(******)\n\n/// Type to store similarities\ntype Neighbour = {\n    /// inverse of distance\n    Similarity: float\n    /// list of source cluster indices\n    Source  : int list\n    /// list of target cluster indices\n    Target  : int list\n    }\n    with static\n            member Create d s t = { Similarity = d; Source = s; Target = t}\n\n//Example queue\nlet neighbours = \n    [|\n    Neighbour.Create 1. [1]      [2]\n    Neighbour.Create 2. [0]      [6]\n    Neighbour.Create 5. [3]     [5]\n    Neighbour.Create 2. [4;7;10] [8;9]\n    Neighbour.Create 7. [1]      [2]\n    |]\n\n////// usage of PriorityQueue\nlet myPQueue = PriorityQueue(neighbours,fun x -\u003E x.Similarity)\nmyPQueue.GetHead                                                                     // reports queues\nmyPQueue.RemoveElement (Neighbour.Create 5. [3] [5])                                 // removes element from queue\nmyPQueue.UpdateElement (Neighbour.Create 2. [0] [6]) (Neighbour.Create 200. [0] [6]) // update element in queue \nmyPQueue.RemoveElementsBy (fun x -\u003E not (List.contains 3 x.Source))                  // update element in queue \nmyPQueue.UpdateBy (fun x -\u003E if x.Similarity \u003E 2. then Neighbour.Create 100. x.Source x.Target else x)// update elements in queue  by given function\n\n////// usage of IntervalHeap\n#r \u0022nuget: C5, 2.5.3\u0022\nopen C5\nlet myHeap : IntervalHeap\u003CNeighbour\u003E = IntervalHeap(MemoryType.Normal)\n\nmyHeap.AddAll(neighbours)                   // adds array of neighbours\nlet max = myHeap.FindMax()                  // finds max value entry\nmyHeap.DeleteMax()                          // deletes max value entry \nmyHeap.Filter (fun x -\u003E x.Similarity = 5.)  // filters entries based on predicate function\n\n\n(**\n  - Some example applications of the PriorityQueue type are shown above.\n  \n  - Generate a priority queue that is descending regarding the similarity. \n\n\n### 3\u003Csup\u003Erd\u003C/sup\u003E step:\n  - Create a clustering list, that contains information of the current clustering state. This could be an \u0060\u0060\u0060int list []\u0060\u0060\u0060 where each of the lists contains indices of clustered data points. Since in the beginning all data points are in its own cluster the clustering list could look as follows: \n\n    - \u0060\u0060\u0060let clusteringList = [|[0];[1];[2];...[n-1]|]\u0060\u0060\u0060\n\n  - When cluster 1 and 2 merge, the clustering list may look like this:\n\n    - \u0060\u0060\u0060let clusteringList = [|[0];[1;2];[];...[n-1]|]\u0060\u0060\u0060\n\n### 4\u003Csup\u003Eth\u003C/sup\u003E step:\n  - Now the agglomeration starts. Since every data point is in its own cluster, you can perform n-1 agglomeration (merging) steps before you result in a single cluster that contains all data points.\n\n  - For each merge (1..n-1) do\n\n    - take the first entry of the priority queue (the most similar clusters)\n\n      - source indices = [i] \n\n      - target indices = [j]\n\n    - Create a new cluster, that contains the merged indices: [i;j]\n\n    - Save the new cluster configuration in your clustering list. Therefore you can add j to the i\u003Csup\u003Eth\u003C/sup\u003E cluster, and you can remove j from the j\u003Csup\u003Eth\u003C/sup\u003E cluster.\n\n    - Remove any entry from priority queue that contains j as target or source index.\n\n    - Update all entries in priority queue that contain i as source or targe index:\n\n      - j has to be added to every cluster that contains i\n\n      - Replace the distances with new distances of the merged mergedCluster to all other clusters.\n\n    - repeat cycle with next merge\n\n### 5\u003Csup\u003Eth\u003C/sup\u003E step:\n\n  - Clustering list now contains all possible cluster configurations. Convert the clustering list into\n  a binary tree structure such as \u0060\u0060\u0060ML.Unsupervised.HierarchicalClustering.Cluster\u003C\u0027a\u003E\u0060\u0060\u0060\n\n\n### 6\u003Csup\u003Eth\u003C/sup\u003E step: Function implementation in F#\n\n  - create a function, that contains all necessary helper functions in its body and takes the following parameters (suggestion):\n\n|Parameter name|data type|description|\n|--------------|---------|-----------|\n|data|\u0060\u0060\u0060seq\u003C\u0027a\u003E\u0060\u0060\u0060|data|\n|distFu|\u0060\u0060\u0060\u0027a-\u003E\u0027a-\u003Efloat\u0060\u0060\u0060|distance Function from \u0060\u0060\u0060FSharp.Stats.ML.DistanceMetrics\u0060\u0060\u0060|\n|linkageType|\u0060\u0060\u0060Linker.LancWilliamsLinker\u0060\u0060\u0060 or self defined|linkage type that is used during clustering|\n||||\n|output|\u0060\u0060\u0060ML.Unsupervised.HierarchicalClustering.Cluster\u003C\u0027a\u003E\u0060\u0060\u0060 or cluster configuration list||\n\n### 7\u003Csup\u003Eth\u003C/sup\u003E step: Further coding considerations\n\n  - Removing elements from the priority queue is slow. Is there a better way to avoid the deletion? \n    \n    - Reference#2 suggests:\n     \n    \u003E There is a repeated removal from Q when i,m are merged. This can be avoided with a new implementation where we maintain multiple priority queues and find the maximum of each priority queue and pick the one with max value. We can ignore the priority queue for m. When considering amortized analysis of this algorithm, this efficiently performs the deletion and restricts the number of calls to Heapify algorithm.\n  \n    - maybe a Map(int[],bool), or a nested priority queue would be beneficial\n\n    - or another implementation of heap/priority queues like C5.IntervalHeap could be faster\n\n## References\n\n- https://www.youtube.com/watch?v=7xHsRkOdVwo\n\n- https://github.com/srirambaskaran/efficient-hierarchical-clustering\n\n- https://nlp.stanford.edu/IR-book/pdf/17hier.pdf\n\n- https://medium.com/machine-learning-researcher/clustering-k-mean-and-hierarchical-cluster-fa2de08b4a4b\n\n\n## Additional information\n\n### Testing\n\n  - apply hClust to a dataset of your choice\n\n  - optional: Test your results against implementations in R/Python or in the best case against the datasets proposed in the original publication.\n\n### Blog post\n\n  - What is solved by the usage of hClust?\n  \n  - classical application examples\n  \n  - limitations/drawbacks of hClust\n\n  - short description of the algorithm (maybe with flowchart visualization)\n\n\n*)"},{"uri":"/BIO-BTE-10-L-4/projects/bioreactorGrowthAnalysis.html","title":"Automated analysis of bioreactor growth curves","content":"(**\n---\ntitle: Automated analysis of bioreactor growth curves\ncategory: projects\ncategoryindex: 2\nindex: 1\n---\n*)\n\n\n(**\n# Automated analysis of bioreactor growth curves\n\n\n#### Table of contents\n\n- [Introduction](#Introduction) \n    - [Input](#Input)\n    - [Output](#Output)\n- [Coding clues](#Coding-clues)\n- [References](#References)\n- [Additional information](#Additional-information)\n\n\n## Introduction\n\n  - The bioreactor in the department of Biotechnology and Systems Biology contains eight individual growth cells that contain the green algae _Chlamydomonas reinhardtii_. Every minute a measurement of the \n  optical density is taken (680 and 750 nm). The reactor operates in turbidostatic mode, indicating that the cells density should be kept constant. If the cells grow, the optical density increases and the \n  reactor has to dilute the growth medium to restore a constant OD750. Please note, that for photosynthetic active organisms you should use OD750, because OD650 lies within the chlorophyll autofluorescence and therefore\n  may be biased.\n\n  - The manual process of analysing the data is quite cumbersome. The exported data set constists of (i) time, (ii) measured OD, and (iii) the activity of the dilution pump. To analyse the growth, the slope of the growth\n  phase OD is required. Therefore, the data is loaded in MS-Excel, the growth phases are manually selected and individually fitted with a straight regression line. The slope of these lines are then used to get an \n  estimate of the average growth rate (inverse slope).\n\n  \n![](../img/odData_1.png)\n_Fig. 1: Schematic view of the data. The saw tooth signals has to be separated into distinct growth-phases. The slope of these lines can be used to estimate the growth rate. The growth changes during the experiment as the slope is lower in the center three growth phases (e.g. the light was turned off and the cells grow slower)._\n\n\n- The aim of this project is to automate this process. A possible solution to this problem is the following:\n  - input: CSV, TXT, or TSV file in which column 1 and 2 contains time data, column 3 the OD, and column 4 the pump data\n  - output: Plotly figure that contains all necessary information to (i) perform a visual quality check of the analysis performace, and (2) further determine growth.\n\n\n \n### Input:\n\n\n  |time(h)|time(absolute)|OD750|pumping volumen|misc|\n  |-------|--------------|-----|---------------|----|\n  |0.00000|2023/10/23 12:45:25|0.657|0.0|...|\n  |0.01667|2023/10/23 12:46:25|0.660|0.0|...|\n  |0.03333|2023/10/23 12:47:25|0.656|0.0|...|\n  |0.05000|2023/10/23 12:48:25|0.650|0.0|...|\n  |0.06667|2023/10/23 12:49:25|0.661|0.0|...|\n  |0.08333|2023/10/23 12:50:25|0.657|0.0|...|\n  |0.10000|2023/10/23 12:51:25|0.658|0.0|...|\n  |0.11667|2023/10/23 12:52:25|0.662|0.0|...|\n  |0.13333|2023/10/23 12:53:25|0.661|0.1|...|\n  \n  \n### Output:\n\n![](../img/odData_2.png)\n_Fig. 2: A possible visual solution_\n\n\n\n## Coding clues\n\n  - start by developing in a jupyter notebook or fsx script. The automatic analysis can be done afterwards by creating a skript, that takes a predefined data set that is stored e.g. at the same location as the script.\n  The output plot can be stored in the same folder with the name containing the current date. In the end you can create a file named \u0022analysis.cmd\u0022 and that just contains \u0022dotnet fsi analysisScriptName.fsx\u0022. By double clicking\n  this file, you start the complete analysis workflow without the need to open any script or do any programming at all.\n  \n  - Import the data and dissect it by using the pumping volume data. Whenever this data is constant you can start collecting OD data for the current growth phase. When the pump starts diluting again, stop collecting data for the \n  current growth data\n\n  - There are various options to fit a line to the data:\n\n    - General usage: https://fslab.org/FSharp.Stats/Fitting.html\n  \n    - (i) Use simple linear regression where the squared distances from the fit to the original data points (residuals) are minimized (OLS regression). \n    The drawback is, that outlier values have a huge impact to the fitting line. \u0060LinearRegression.fit(testDataX, testDataY, FittingMethod = Method.SimpleLinear)\u0060\n\n    - (ii) You can use outlier insensitive slope determination methods (e.g. Theil-Sen estimator). \n    The drawback is, that outlier values have a huge impact to the fitting line. \u0060LinearRegression.fit(testDataX, testDataY, FittingMethod = Method.Robust RobustEstimator.TheilSen)\u0060\n\n    - (iii) Use simple linear regression but remove outliers after the initial fit and fit again ignoring the outliers. \n    e.g. use [cooks distance](https://fslab.org/FSharp.Stats/GoodnessOfFit.html#Cook-s-distance) for outlier detection\n\n  - Use Plotly.NET for visualization\n    - For the BoxPlot you can use \u0060Chart.BoxPlot(Y = [2.;3.4], Name = \u0022slopes\u0022,Jitter=0.2,BoxPoints=StyleParam.BoxPoints.All,BoxMean=StyleParam.BoxMean.True)\u0060 to additionally view all data points and the data mean.\n\n\nThe following plotting example contains much of the functionality you\u0027ll need, but not necessarily in the correct position. I would suggest for each fitting strategy (OLS, robust, ...) to generate an individual output plot.\n\n\n*)\n\n(******)\n\n#r \u0022nuget: FSharp.Stats, 0.5.0\u0022\n#r \u0022nuget: Plotly.NET, 4.2.0\u0022\n            \nopen FSharp.Stats\nopen Plotly.NET\nopen FSharp.Stats.Fitting\n\nlet xs = vector [|1. .. 10.|]\nlet ys = vector [|4.;10.;9.;7.;13.;17.;16.;23.;15.;30.|]\n\nlet fitA = Fitting.LinearRegression.fit(xs,ys,FittingMethod=Fitting.Method.SimpleLinear)\nlet fitB = Fitting.LinearRegression.fit(xs,ys,FittingMethod=Fitting.Method.Robust RobustEstimator.TheilSen)\n\n\n\nlet description = \n    // some styling for a html table\n    let style = \u0022\u003Cstyle\u003Etable {font-family: arial, sans-serif;border-collapse: collapse;width: 75%;}td, th {border: 1px solid #dddddd;text-align: left;padding: 8px;}tr:nth-child(even) {background-color: #dddddd;}\u003C/style\u003E\u0022\n    \n    // header row of the table\n    let header = \u0022\u003Ctr\u003E\u003Cth\u003EPhase ID\u003C/th\u003E\u003Cth\u003ETime span start (h)\u003C/th\u003E\u003Cth\u003ETime span end (h)\u003C/th\u003E\u003Cth\u003ESlope (t\u003Csup\u003E-1\u003C/sup\u003E\u003C/th\u003E\u003C/tr\u003E\u0022\n    \n    // table rows\n    let rows = \n        [fitA;fitB]\n        |\u003E List.mapi (fun i x -\u003E \n            // create a table row with phase id, the start and end of the treatment formatted as a float with one significant figure (defined by %.1f) and the slope with four significant figures.\n            // the slope is stored within the fit coefficients as [intersect;slope]\n            $\u0022\u003Ctr\u003E\u003Ctd\u003E{i \u002B 1}\u003C/td\u003E\u003Ctd\u003E%.1f{Seq.head xs}\u003C/td\u003E\u003Ctd\u003E%.1f{Seq.last xs}\u003C/td\u003E\u003Ctd\u003E%.4f{x.Coefficients.[1]}\u003C/td\u003E\u003C/tr\u003E\u0022\n        )\n\n    // constructed table\n    let table = $\u0022{style}\u003Ctable\u003E{header}{rows}\u003C/table\u003E\u0022\n\n    // convert the table string to a giraffe node element to be compatible with Plotly.NET\n    Giraffe.ViewEngine.HtmlElements.rawText table\n\n\n\nlet chart = \n    [\n        [\n            Chart.Point(x=xs,y=ys,Name=\u0022raw data\u0022,MarkerColor=Color.fromHex \u0022#1e1e1e\u0022)\n            Chart.Line(x=[1.;10.],y=[fitA.Predict 1.;fitA.Predict 10.;],Name=\u0022OLS fit\u0022,LineColor=Color.fromHex \u0022#1f77b4\u0022)\n        ]\n        |\u003E Chart.combine\n\n        [\n            Chart.Point(x=xs,y=ys,Name=\u0022raw data\u0022,MarkerColor=Color.fromHex \u0022#1e1e1e\u0022)\n            Chart.Line(x=[1.;10.],y=[fitB.Predict 1.;fitB.Predict 10.;],Name=\u0022TheilSen fit\u0022,LineColor=Color.fromHex \u0022#ff7f0e\u0022)\n        ]\n        |\u003E Chart.combine\n\n    ]\n    |\u003E Chart.Grid(nRows=2,nCols=1)\n    |\u003E Chart.withTemplate ChartTemplates.lightMirrored\n    |\u003E Chart.withConfig (\n        Config.init (ToImageButtonOptions = ConfigObjects.ToImageButtonOptions.init(Format = StyleParam.ImageFormat.SVG))\n        )\n    |\u003E Chart.withDescription [description]\n\nchart\n|\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\n![](../img/odData_3.png)\n\n_Fig. 3: Example of Plotly.NET combined graphs_\n\n\n## References\n\n  - [Plotly.NET documentation](https://plotly.net/)\n\n  - [FSharp.Stats documentation](https://github.com/fslaborg/FSharp.Stats)\n\n\n## Additional information\n\n  - None\n\n*)\n\n"},{"uri":"/BIO-BTE-10-L-4/projects/evolutionary-distance.html","title":"Phylogenetic tree reconstruction based on evolutionary distance","content":"(**\n---\ntitle: Phylogenetic tree reconstruction based on evolutionary distance\ncategory: projects\ncategoryindex: 2\nindex: 3\n---\n*)\n\n(**\n# Phylogenetic tree reconstruction based on evolutionary distance\n    \n**Interested?** Contact [muehlhaus@bio.uni-kl.de](mailto:muehlhaus@bio.uni-kl.de) or [schneike@bio.uni-kl.de](mailto:schneike@bio.uni-kl.de)\n\n#### Table of contents\n\n- [Introduction](#Introduction) \n    - [Phylogenetic trees](#Phylogenetic-trees)\n    - [Evolutionary Distance of DNA sequences](#Evolutionary-Distance-of-DNA-sequences)\n        - [Proportional distance](#Proportional-distance)\n    - [Distance Corrections based on evolutionary Models](#Distance-Corrections-based-on-evolutionary-Models)\n        - [The Jukes-Cantor Model](#The-Jukes-Cantor-Model)\n        - [The Kimura 2-Parameter Model](#The-Kimura-2-Parameter-Model)\n- [Aim for this project](#Aim-for-this-project)\n- [Coding clues](#Coding-clues)\n    - [Before you start](#Before-you-start)\n    - [Scripting environment and necessary libraries](#Scripting-environment-and-necessary-libraries)\n    - [General coding advice](#General-coding-advice)\n- [References](#References)\n- [Additional information](#Additional-information)\n    - [Testing](#Testing)\n    - [Blog post](#Blog-post)\n\n## Introduction\n\n### Phylogenetic trees\n\nPhylogenetic trees are diagrams that visualize inferred evolutionary relationships between a set of organisms. Consider this tree diagram:\n\n\u0060\u0060\u0060\n         ____ A\n       _|\n      | |____ B\n______|\n      |______ C\n\u0060\u0060\u0060\n\nAncestors are shown as nodes on the tree, while the leaves represent the respective organisms.\nIt tells you that A and B share a common ancestor, and that that ancestor shares a common ancestor with C. \nIn other words, A and B are closer related to each other, than each of them to C.\n\nA and B form a _clade_ together with their common ancestor (also known as a _monophyletic group_) - a group of organisms that includes a single ancestor \nand all of its descendents that represent unbroken lines of evolutionary descent. \n\nBut based on what information do we construct such trees? There are different classes of approaches to this problem, but to stay beginner-friendy, \nonly _distance-based_ methods will be discussed in the scope of this project. For sake of completeness, other approaches include _parsimony_, \n_maximum likelihood_ and _Bayesian approaches_ to searching the possible tree space.\n\nThe first step in any (distance-based) phylogenetic tree reconstruction is the selection of the characteristic to infer evolutionary relationships from, \nand subsequently the determination of the phylogenetic distance between the organisms of interest based on that characteristic.\n\n\u003Cbr\u003E\n\n---\n\n### Evolutionary Distance of DNA sequences\n\nAny kind of characteristic of organisms can be used to try to infer phylogenetic relationships - like for example beaks of Darwin finches -\nbut DNA sequences have proven to be incredibliy helpful to reconstruct phylogenetic trees, as the nucleotide alphabet is relatively \nsimple and sequencing data has reached unparalleled throughput and accuracy. Likewise, there are a wide range of sophisticated methods to \ncalculate phylogenetic distance based on DNA sequences. \n\nIn the scope of this project, you will take a step back and look at some classic evolutionary models that can be used to model phylogenetic \ndistance based on DNA sequences.\n\nA few important bits of jargon for the following chapters:\n\n- DNA substitution mutations can be classified by 2 types:\n    - _Transitions_ are interchanges of two-ring purines (A \u003C\u003E G) or of one-ring pyrimidines (C \u003C\u003E T)\n    - _Transversions_ are interchanges of purine for pyrimidine bases or vice versa (A \u003C\u003E T | A \u003C\u003E C | G \u003C\u003E T | G \u003C\u003E C)\n\n\u003Cimg style=\u0022max-width:30%\u0022 src=\u0022../img/transitions-transversions.svg\u0022\u003E\u003C/img\u003E\n\n\u003Cbr\u003E\n\n---\n\n#### Proportional distance\n\nThe pairwise proportional distance (or _p distance_) is the classical \u0027naive\u0027 approach to estimate pairwise distances between two sequences. \n\nIt is simply the ratio between substitution sites and the length of the sequences. Note that - as in all distances you will implement - both \nsequences have to be of the same length or have to be aligned before calculating distances. It is obtained by dividing the amount of substitutions \nby the total amount of compared nucleotides:\n\n$p = \\frac{d}{L},$\n\nwhere \n\n$d = s \u002B v$\n\n$s : Transitions$\n\n$v : Transversions$\n\n$L : length$\n\nWhat are the advantages and weaknesses of this approach? Inform yourself.\n\n\u003Cbr\u003E\n\n---\n\n### Distance Corrections based on evolutionary Models\n\nTo overcome the shortcomings of the simple proportional distance, many evolutionary models for biological sequences are available.\nMost of the time, sequence evolution by mutation is described as a stochastic process modelled by continuous-time Markov chains, with \nthe alphabet (for DNA: _A, C, G, T_) as possible states.\n\nFor any sequence position, these models are then defining a substitution probability matrix based that acts as the stochastic matrix of the markov chain.\n\nA basic understanding of markov chains may be beneficial, but not necessary. It is just important that these models define probabilities \nfor transitions and transversions, and can be solved for a corrected pairwise distance that suffices the model substitution criteria.\n\n\u003Cbr\u003E\n\n---\n\n#### The Jukes-Cantor Model\n\nThe Jukes-Cantor model is the simplest form of these kinds of models. It makes no difference between transitions and transversions, \nmeaning that all substitutions have the same substitution rate ($\\alpha$). Also, all sites are modelled independently.\n\nThe substitution matrix is:\n\n$$$\n\\begin{matrix}\n\u0026 \\begin{matrix}A \u0026 \u0026 C \u0026 \u0026 G \u0026 \u0026 T\\end{matrix} \\\\\\\\\n\\begin{matrix}A\\\\\\\\C\\\\\\\\G\\\\\\\\T\\end{matrix} \u0026 \n  \\begin{pmatrix}\n    -3\\alpha\u0026\\alpha\u0026\\alpha\u0026\\alpha\\\\\\\\\n    \\alpha\u0026-3\\alpha\u0026\\alpha\u0026\\alpha\\\\\\\\\n    \\alpha\u0026\\alpha\u0026-3\\alpha\u0026\\alpha\\\\\\\\\n    \\alpha\u0026\\alpha\u0026\\alpha\u0026-3\\alpha\n  \\end{pmatrix}\\\\\\\\\n\\end{matrix}\n\n$3\\alpha t$ mutations would be expected during a time $t$ for each sequence site on each sequence, leading to\na correction factor for the proportional distance $d_{JC}$ :\n\n$$d_{JC}=-\\frac{3}{4}ln(1-\\frac{4}{3}p)$$\n\nWhat are the advantages and weaknesses of this approach? Inform yourself.\n\n\u003Cbr\u003E\n\n\n\n---\n\n#### The Kimura 2-Parameter Model\n\nThe substitution matrix is:\n\n$$$\n\\begin{matrix}\n\u0026 \\begin{matrix}A \u0026 \u0026 \u0026 \u0026 C \u0026 \u0026 \u0026 \u0026 G \u0026 \u0026 \u0026 \u0026 T\\end{matrix} \\\\\\\\\n\\begin{matrix}A\\\\\\\\C\\\\\\\\G\\\\\\\\T\\end{matrix} \u0026 \n  \\begin{pmatrix}\n    -2\\beta-\\alpha\u0026\\beta\u0026\\alpha\u0026\\beta\\\\\\\\\n    \\beta\u0026-2\\beta-\\alpha\u0026\\beta\u0026\\alpha\\\\\\\\\n    \\alpha\u0026\\beta\u0026-2\\beta-\\alpha\u0026\\beta\\\\\\\\\n    \\beta\u0026\\alpha\u0026\\beta\u0026-2\\beta-\\alpha\n  \\end{pmatrix}\\\\\\\\\n\\end{matrix}\n\nIt results in a corrected distance $d_{K2P}$:\n\n$d_{K2P}=-\\frac{1}{2}ln(1-2P-Q)-\\frac{1}{4}ln(1-2Q)$,\n\nwhere\n\n$P=\\frac{s}{L}$\n\n$Q=\\frac{v}{L}$\n\nWhat are the advantages and weaknesses of this approach? Inform yourself.\n\n\u003Cbr\u003E\n\n---\n\n## Aim for this project\n\n- You understand the following evolutionary distance models and are able to explain the differences between them (required in your final report)\n    Also, you implement them in F# for the BioFSharp library:\n\n    - Pairwise p Distance\n    - JC69 evolutionary distance based on the model by Jukes and Cantor\n    - K81 evolutionary distance based on the Kimura two-parameter model\n\n- As a demonstration of your implementations, as well as to show the differences between these models,\n    You construct at least 10 adequate test sequences of equal length, and construct phyologenetic trees from them. \n    Investigate the most interesting and obvious differences, and relate them to the different model assumptions.\n\n- Finally, you choose adequate sequences of at least 6 organisms, perform a multiple alignment for them and repeat above process for real-world sequences.\n\n- You present above results in a blog post resembling your final report.\n\n- **Bonus**: You implement a visualization method for phylogenetic trees for [Cyjs.NET](https://fslab.org/Cyjs.NET/). \n\n## Coding clues\n\n### Before you start \n\n- (re)familiarize yourself with the basics behind phylogenetic trees.\n\n- (re)familiarize yourself with F# function signatures and the basics of F# programming.\n\n- A basic understanding of Markov chains is beneficial, but not necessary.\n\n### Scripting environment and necessary libraries\n\n- create a F# script (.fsx), load and open the following libraries:\n    - \u0060FSharpAux\u0060\n    - \u0060FSharpAux.IO\u0060\n    - \u0060FSharp.Stats\u0060\n    - \u0060BioFSharp\u0060\n    - \u0060BioFSharp.IO\u0060\n    - \u0060Plotly.NET\u0060\n\nthe top of your script file should look like this:\n*)\n\n#r \u0022nuget: FSharpAux, 1.1.0\u0022\n#r \u0022nuget: FSharpAux.IO, 1.1.0\u0022\n#r \u0022nuget: FSharp.Stats, 0.4.3\u0022 \n#r \u0022nuget: BioFSharp, 2.0.0-preview.1\u0022\n#r \u0022nuget: BioFSharp.IO, 2.0.0-preview.1\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.16\u0022\n\nopen FSharpAux\nopen FSharpAux.IO\nopen BioFSharp\nopen BioFSharp.IO\nopen FSharp.Stats\nopen Plotly.NET\n\n(**\n\n### General coding advice\n\n- All pairwise distance functions should be able to operate on either \u0060BioArray\u0060, \u0060BioList\u0060, or \u0060BioSeq\u0060. \nYou can use the fact that all of these sequence types are implementing \u0060IEnumerable\u0060 and can only contain nucleotides.\n\n\u003Cbr\u003E\n\n---\n\n- To perform hierarchical clustering to reconstruct the phylogenetic trees, use the respective module from the \u0060BioFSharp\u0060 library \n(\u0060PhylogeneticTree\u0060 functions) and work with \u0060TaggedSequence\u0060s:\n\n\u003Cbr\u003E\n\n*)\n\n(***hide***)\nlet yourSequences: seq\u003CTaggedSequence\u003Cstring,Nucleotides.Nucleotide\u003E\u003E = []\n\n(***do-not-eval***)\nopen BioFSharp\n\n(***do-not-eval***)\nlet yourDistance (seqA: seq\u003C#IBioItem\u003E) (seqB:seq\u003C#IBioItem\u003E) = 42. //do real distance calculations here\n\n(***do-not-eval***)\n//reconstruct a phylogenetic tree from tagged sequences\nlet myTree =\n    PhylogeneticTree.ofTaggedBioSequences\n        yourDistance // your distance function for either p, JC69, or K81 distance\n        yourSequences // your adequate nucleotide test sequences as tagged sequences \n\n(**\n\u003Cbr\u003E\n\n---\n\n- to perform Multiple sequence alignment between your real world sequence examples, use the respective functions from \u0060BioFSharp\u0060:\n\n    For that, you have to first install [clustal omega](http://www.clustal.org/omega/clustal-omega-1.2.2-win64.zip), a very nice multiple sequence aligment tool. \n    You can use it directly in F# interactive via BioFSharp\u0027s \u0060ClustalOWrapper\u0060:\n\n\u003Cbr\u003E\n\n*)\n\nopen ClustalOWrapper\nlet cw = ClustalOWrapper(\u0022path/where/you/extracted/clustal-omega-1.2.2-win64/clustalo.exe\u0022) // replace with real path from your machine here!\n\nlet sequences = \n    [\n    TaggedSequence.create \u0022seq1\u0022 (\u0022ATGAAAAA\u0022)\n    TaggedSequence.create \u0022seq2\u0022 (\u0022ATGAAACA\u0022)\n    TaggedSequence.create \u0022seq3\u0022 (\u0022ATGAAAAAAT\u0022)\n    TaggedSequence.create \u0022seq4\u0022 (\u0022ATGGAAAA\u0022)\n    ]\n\nlet alignedSequences = \n    cw.AlignSequences(sequences,Seq.empty)\n\n(**\n\u003Cbr\u003E\n\n---\n\n- There are two ways of handling the gaps produced by alignments: _Complete-Deletion_ and _Pairwise Deletion_ inform yourself about them.  \n\n    _Hint1_: The output of above alignment contains conservation information about the alignment. \n\n    _Hint2_: You might want to add an additional parameter to your distance function modelling this behaviour. For that, use a Discriminated Union type.\n\n\u003Cbr\u003E\n\n---\n\n- Here is a suggestion for the general workflow for the real-world sequences:\n\n\u003E**Suggested workflow**\n\u003E\n\u003ERead your fasta formatted sequences\n\u003E\n\u003EPerform multiple sequence alignment $A$\n\u003E\n\u003Efor each implemented distance function $dist$:\n\u003E\n\u003E$\\quad$reconstruct phylogenetic tree for $A$ with $dist$ function\n\u003E\n\u003E$\\quad$Write as newick format\n\u003E\n\u003E$\\quad$Visualize tree, for example on http://etetoolkit.org/treeview/\n\n---\n\n*)\n\n\n(**\n\n---\n\n## References\n\nNei, M. \u0026 Zhang J. Evolutionary Distance: Estimation 2006 https://doi.org/10.1038/npg.els.0005108\n\nhttps://en.wikipedia.org/wiki/Models_of_DNA_evolution\n\nhttps://www.cs.rice.edu/~nakhleh/COMP571/Slides/Phylogenetics-DistanceMethods-Full.pdf\n\nhttps://www.megasoftware.net/web_help_10/index.htm#t=Models_for_estimating_distances.htm\n\nhttps://www.megasoftware.net/mega1_manual/Distance.html\n\n## Additional information\n\n### Testing\n\n  - the [MEGA software suit](https://www.megasoftware.net/active_download) contains many evolutionary distance functions. \n    You can use it as reference implementation to check wether your functions return correct results. To do that, download the GUI version, install it,\n    and follow these steps:\n\n    - Click the \u0060Distances\u0060 button and choose \u0060pairwise distance\u0060:\n\n        ![](../img/mega1.png)\n\n    - Select a fasta file containing the sequences of interest, and choose the reference model from this dialogue:\n\n        ![](../img/mega2.png)\n\n### Blog post \n\n  - Don\u2019t forget to describe the limits/weaknesses of the models in your blog post.\n\n  - How to handle gaps in aligned sequences?\n\n  - Provide reasoning why you chose your real world sequences\n\n*)"},{"uri":"/BIO-BTE-10-L-4/projects/PrimsAlgorithm.html","title":"Reduce complex graphs to the best paths","content":"(**\n---\ntitle: Reduce complex graphs to the best paths\ncategory: projects\ncategoryindex: 2\nindex: 4\n---\n*)\n\n(**\n# Reduce complex graphs to the best paths\n\n**Interested?** Contact [muehlhaus@bio.uni-kl.de](mailto:muehlhaus@bio.uni-kl.de) or [weil@bio.uni-kl.de](mailto:weil@bio.uni-kl.de)\n\n#### Table of contents\n\n- [Introduction](#Introduction)\n    - [Minimum spanning trees](#Minimum-spanning-trees) \n    - [Prim\u0027s algorithm](#Prim-s-algorithm) \n- [Aim for this project](#Aim-for-this-project)\n- [References](#References)\n- [Coding clues](#Coding-clues)\n- [Additional information](#Additional-information)\n    - [Testing](#Testing) \n    - [Blog post](#Blog-post) \n\n## Introduction\n\n\u0060Imagine you\u0027re elected Minister of Infrastructure and tasked to build a road grid. This grid is supposed to connect all cities. Your budget is pretty tight though so the combined length of the roads should be as low as possible\u0060\n\nProblem\u0027s like this are predetermined to be regarded as a graph problem. Graphs are structures that consist of two different kinds of components:\n- Vertices are the entities of the graph\n- Edges connect these vertices\n\nAlthough simple in principal, graphs can become complex as they grow. Graph algorithms have emerged for all kinds of problems. One of them is finding minimum spanning trees which have been used to solve the problem described in the beginning.\n\n### Minimum spanning trees\n\nA minimum spanning tree (MST) or minimum weight spanning tree is a subset of the edges of a connected, edge-weighted undirected graph that connects all the vertices together, without any cycles and with the minimum possible total edge weight.\n\nAs indicated above, MSTs have applications everytime someone needs to design an efficient grid. Examples for this might be electric grids, road grids or water pipe grids. \nBesides that, MSTs can be used for studying epidemeology by finding the shortest paths trough which pathogens might traverse a population network.\n\nIn biological research, MSTs might be used for visualization or clustering purposes. An example for this can be seen in the picture below, where phylogenetic groups were found and visualized using an MST.\n\n\u003Cimg src=\u0022../img/Prims_MST.png\u0022 alt=\u0022drawing\u0022 width=\u002245%\u0022/\u003E\n\u003Cimg src=\u0022../img/Prims_Phylo.png\u0022 alt=\u0022drawing\u0022 width=\u002245%\u0022/\u003E\n\n\u003Cbr\u003E\n\nSeveral algorithms exist for finding MST, where often there is a tradeoff made between performance and quality of the result. Your task will be to implement one of them.\n\n### Prim\u0027s algorithm\n\nPrim\u0027s algorithm is a simple, greedy approach for finding the MST of a network. Greedy approaches always find the best solution in exchange for lower performance. \n\nIn Prim\u0027s algorithm, you start a new graph by selecting a single vertex in the original graph. This new graph is repetitively grown by finding the closest connections to vertices not yet included in the MST.\n\n![](../img/Prims_Demo.gif)\n\n## Aim for this project\n\n\u003Cbr\u003E\n\n- Get a basic understanding of network science\n\n- Implement Prim\u0027s algorithm for finding minimum spanning trees\n\n- Write a blogpost entry \n\n## References\n\n- [Introduction to graphs and networks](http://networksciencebook.com/chapter/2#networks-graphs)\n- [Minimum spanning tree](https://en.wikipedia.org/wiki/Minimum_spanning_tree)\n- [Prim\u0027s algorithm](https://en.wikipedia.org/wiki/Prim%27s_algorithm)\n- [Graph Visualization](https://fslab.org/Cyjs.NET/)\n\n## Coding clues\n\n### General steps:\n\n1. Initialize a tree with a single vertex, chosen arbitrarily from the graph.\n2. Grow the tree by one edge: of the edges that connect the tree to vertices not yet in the tree, find the minimum-weight edge, and transfer it to the tree.\n3. Repeat step 2 (until all vertices are in the tree).\n\n### Using the graph library:\n\n*)\n\n#r \u0022nuget: FSharp.FGL, 0.0.2\u0022\n\nopen FSharp.FGL\nopen FSharp.FGL.Undirected\n\n// Create a new graph\nlet g : Graph\u003Cint,string,float\u003E = Graph.empty\n\n\n// Add vertices \nlet v1 = (1,\u0022VertexNumeroUno\u0022)\nlet v2 = (2,\u0022VertexNumeroDos\u0022)\n\nlet gWithVertices = \n    Vertices.add v1 g\n    |\u003E Vertices.add v2\n\n// Add edges\nlet e = (1,2,1.)\n\nlet gWithEdge = \n    Edges.add e gWithVertices\n\n// Show all edges to find the best\nEdges.toEdgeList\n\n// Remove vertex (Including its edges)\nVertices.remove (fst v1) gWithEdge\n\n(**\n### Visualize the graph:\n*)\n\n#r \u0022nuget: Cyjs.NET, 0.0.4\u0022\n\nopen Cyjs.NET\n\nlet inline toCyJS (g : Graph\u003C\u0027Vertex,\u0027Label,float\u003E) =\n    let vertices = \n        g\n        |\u003E Vertices.toVertexList\n        |\u003E List.map (fun (id,name) -\u003E Elements.node (string id) [CyParam.label (string name)])\n\n    let edges =\n        g\n        |\u003E Edges.toEdgeList\n        |\u003E List.map (fun (v1,v2,weight) -\u003E Elements.edge (string v1 \u002B string v2) (string v1) (string v2) [CyParam.weight (weight)])\n\n    CyGraph.initEmpty ()\n    |\u003E CyGraph.withElements vertices\n    |\u003E CyGraph.withElements edges\n    |\u003E CyGraph.withStyle \u0022node\u0022 [CyParam.content =. CyParam.label]\n    |\u003E CyGraph.withStyle \u0022edge\u0022 [CyParam.content =. CyParam.weight]\n\n(***do-not-eval***)\ngWithEdge\n|\u003E toCyJS\n|\u003E CyGraph.show\n\n(**\n\u003Cbr\u003E\n\n#### The visualized graph should look as follows:\n*)\n\n(*** hide ***)\ngWithEdge\n|\u003E toCyJS\n|\u003E CyGraph.withSize(600, 400) \n|\u003E Cyjs.NET.HTML.toEmbeddedHTML\n(*** include-it-raw ***)\n\n(** \n## Additional information\n\n### Testing\n\nFor testing whether your implementation does return the correct results, you can use this website: \n\nhttps://algorithms.discrete.ma.tum.de/graph-algorithms/mst-prim/index_en.html\n\n![](../img/Prims_Testing.png)\n\n### Blog post\n\n- What is a minimum spanning tree\n- Classical application examples\n- Advantages and drawbacks of Prim\u0027s algorithm\n- Short description of the algorithm\n\n*)"},{"uri":"/BIO-BTE-10-L-4/projects/sequencingByHybridization.html","title":"Sequencing by Hybridization as an Eulerian Path Problem","content":"(**\n---\ntitle: Sequencing by Hybridization as an Eulerian Path Problem\ncategory: projects\ncategoryindex: 2\nindex: 5\n---\n*)\n\n\n(**\n# Sequencing by Hybridization as an Eulerian Path Problem\n\n**Interested?** Contact [muehlhaus@bio.uni-kl.de](mailto:muehlhaus@bio.uni-kl.de) or [ottj@rhrk.uni-kl.de](mailto:ottj@rhrk.uni-kl.de)\n\n#### Table of contents\n\n- [Introduction](#Introduction) \n- [Aim for this project](#Aim-for-this-project)\n- [Coding clues](#Coding-clues)\n- [References](#References)\n- [Additional information](#Additional-information)\n    - [Testing](#Testing)\n    - [Blog post](#Blog-post)\n\n\n## Introduction\n\nSequencing by Hybridization (SBH) involves building a miniature DNA array (or DNA chip), that contains thousands of short DNA fragments (probes). Each of these probes gives information about the presence \nof a known, but short, sequence in the unknown DNA sequence. All these pieces of information together should reveal the identity of the target DNA sequence. \nGiven a short probe (an 8- to 30-nucleotide single-stranded synthetic DNA fragment) and a single-stranded target DNA fragment, the target will hybridize \nwith the probe if the probe is a substring of the target\u0027s complement. When the probe and the target are mixed together, they form a \nweak chemical bond and stick together. For example, a probe ACCGTGGA will hybridize to a target CCC**TGGCACCT**A since it is complementary to the substring TGGCACCT of the target.\n\nGiven an unknown DNA sequence, an array provides information about all strings of length *l* (l-mer) that the sequence contains, but does not provide information \nabout their positions in the sequence. For example, the 8-mer composition of CCCTGGCACCTA is {CCCTGGCA, CCTGGCAC, CTGGCACC, TGGCACCT,GGCACCTA} \nThe reduction of the SBH problem to an [Eulerian Path](https://en.wikipedia.org/wiki/Eulerian_path) problem is to construct a graph whose edges, \nrather than vertices, correspond to those l-mers, and then to find a path in this graph visiting every edge exactly once. Paths visiting **ALL EDGES** correspond to sequence reconstructions.\n\n## Aim for this project\n\n1. Blog post introducing the method, its applications, and limitations.\n\n2. Implement a function which creates a directed graph from a given set of l-mers\n\n3. Implement [Hierholzer\u0027s algorithm](https://www-m9.ma.tum.de/graph-algorithms/hierholzer/index_en.html#tab_ti) for finding Eulerian paths in **directed** graphs\n\n\n## Coding clues\n\n### Setting up the environment\n\n* Create a F# script file (.fsx) and paste the following text at the top of your file:\n\n\u0060\u0060\u0060\n#r \u0022nuget: FSharpAux, 1.1.0\u0022\n#r \u0022nuget: BioFSharp, 2.0.0-preview.1\u0022\n#r \u0022nuget: FSharp.FGL, 0.0.2\u0022\n#r \u0022nuget: Cyjs.NET, 0.0.4\u0022\n\nopen FSharpAux\nopen BioFSharp\nopen FSharp.FGL\nopen FSharp.FGL.Directed\nopen Cyjs.NET\n\u0060\u0060\u0060\n\n### Creating an Eulerian Graph of l-mers with FSharp.FGL\n\n* Vertices correspond to (l-1)-mers\n* Edges correspond to l-mers from the spectrum\n* All functions should operate on either \u0060BioArray\u0060, \u0060BioList\u0060 or \u0060BioSeq\u0060\n*)\n(***hide***)\n#r \u0022nuget: FSharpAux, 1.1.0\u0022\n#r \u0022nuget: BioFSharp, 2.0.0-preview.1\u0022\n#r \u0022nuget: FSharp.FGL, 0.0.2\u0022\n#r \u0022nuget: Cyjs.NET, 0.0.4\u0022\n\nopen FSharpAux\nopen BioFSharp\nopen BioFSharp.Nucleotides\nopen FSharp.FGL\nopen FSharp.FGL.Directed\nopen Cyjs.NET\n(**\n\u003Cbr\u003E\n\n* Start with any Nucleotide array\n\n\u003Cbr\u003E\n*)\nlet sampleSequence: array\u003CNucleotide\u003E = \n    \u0022ATGGCGTGCA\u0022\n    |\u003E BioArray.ofNucleotideString\n(**\n\u003Cbr\u003E\n\n* Compute the l-mers of the Nucleotide array (in this case 3-mers)\n\n\u003Cbr\u003E\n*)\nlet lMers3: array\u003Carray\u003CNucleotide\u003E\u003E = \n    [|[|A;T;G|]; [|T;G;G|]; [|T;G;C|]; [|G;T;G|]; [|G;G;C|]; [|G;C;A|]; [|G;C;G|]; [|C;G;T|]|]\n(**\n\u003Cbr\u003E\n\n* Initialize a directed graph\n\n\u003Cbr\u003E\n*)\nlet graph: Graph\u003Cint,array\u003CNucleotide\u003E,array\u003CNucleotide\u003E\u003E = Graph.empty\n(**\n\u003Cbr\u003E\n\n* Create a list with vertices based on the l-mers and add them to the graph\n\n\u003Cbr\u003E\n*)\nlet vertices: list\u003Cint*array\u003CNucleotide\u003E\u003E =\n    [(1, [|A; T|]); (2, [|T; G|]); (3, [|G; T|]); (4, [|G; G|]); (5, [|G; C|]);(6, [|C; G|]); (7, [|C; A|])]\n\nlet graphWithVertices: Graph\u003Cint,array\u003CNucleotide\u003E,array\u003CNucleotide\u003E\u003E =\n    Vertices.addMany vertices graph\n(**\n\u003Cbr\u003E\n\n* Create a list with edges based in the vertices and l-mers and add them to the graph\n\n\u003Cbr\u003E\n*)\nlet edges: list\u003Cint*int*array\u003CNucleotide\u003E\u003E=\n    [(1, 2, [|A; T; G|]); (2, 4, [|T; G; G|]); (2, 5, [|T; G; C|]); (3, 2, [|G; T; G|]);\n    (4, 5, [|G; G; C|]); (5, 7, [|G; C; A|]); (5, 6, [|G; C; G|]); (6, 3, [|C; G; T|])]\n\nlet graphWithEdges: Graph\u003Cint,array\u003CNucleotide\u003E,array\u003CNucleotide\u003E\u003E =\n    Edges.addMany edges graphWithVertices\n(**\n\u003Cbr\u003E\n\n* You can visualize the graph using Cyjs.NET\n\n\u003Cbr\u003E\n*)\nlet inline toCyJS (g : Graph\u003C\u0027Vertex,array\u003CNucleotide\u003E,array\u003CNucleotide\u003E\u003E) =\n    let vertices = \n        g\n        |\u003E Vertices.toVertexList\n        |\u003E List.map (fun (id,name) -\u003E\n            Elements.node (string id) [CyParam.label (name |\u003E BioArray.toString)]\n        )\n\n    let edges =\n        g\n        |\u003E Edges.toEdgeList\n        |\u003E List.map (fun (v1,v2,weight) -\u003E \n            Elements.edge (string v1 \u002B string v2) (string v1) (string v2) [CyParam.weight (weight |\u003E BioArray.toString)]\n        )\n\n    CyGraph.initEmpty ()\n    |\u003E CyGraph.withElements vertices\n    |\u003E CyGraph.withElements edges\n    |\u003E CyGraph.withLayout (Layout.initBreadthfirst id)\n    |\u003E CyGraph.withStyle \u0022node\u0022 [CyParam.content =. CyParam.label]\n    |\u003E CyGraph.withStyle \u0022edge\u0022     \n                [\n                    CyParam.Curve.style \u0022bezier\u0022\n                    CyParam.opacity 0.666\n                    CyParam.width \u003C=. (CyParam.weight, 70, 100, 5, 5)\n                    CyParam.Target.Arrow.shape \u0022triangle\u0022\n                    CyParam.Line.color =. CyParam.color\n                    CyParam.Target.Arrow.color =. CyParam.color\n                    CyParam.Source.Arrow.color =. CyParam.color\n                ]\n\ngraphWithEdges\n|\u003E toCyJS\n\n(***hide***)\ngraphWithEdges |\u003E toCyJS |\u003E CyGraph.withSize(600, 400) |\u003E Cyjs.NET.HTML.toEmbeddedHTML\n(***include-it-raw***)    \n(**\n* This graph is semibalanced \u0060(|indegree - outdegree| = 1)\u0060. If a graph has an Eulerian path starting at vertex *s* and ending at vertex *t*, then all its vertices are balanced, \nwith the possible exception of *s* and *t*, which may be semibalanced.\n\n* The Eulerian path problem can be reduced to the Eulerian cycle problem by adding an edge between two semibalanced vertices.\n\n### Hierholzer\u0027s algorithm\n\n* Choose any starting vertex, and follow a path along the unused edges from that vertex until you return to it. You will alway return to the starting vertex in a balanced Eulerian graph. \nSince every vertex has \u0060indegreee = outdegree\u0060, there is always an unused edge to leave the current vertex. The path found by doing this is a closed tour, starting and ending at the same vertex, \nbut not necessarily covering all vertices and edges.\n\n* As long as there exists a vertex in the current closed tour that has unused edges, you can start finding a new closed tour and join it with the previously found tour.\n\n* Since we assume the original graph is connected, repeating the previous step will cover all edges of the graph.\n\n* Implement the algorithm, so that it works on a \u0060FSharp.FGL.Graph\u0060\n\n### Working with \u0060FSharp.FGL.Graph\u0060s\n\n* Returns all outward edges of vertex 1\n\n*)\nGraph.getContext 1 graphWithEdges\n|\u003E Vertices.outwardEdges\n(***include-it***)\n(**\n\u003Cbr\u003E\n\n* Returns all inward edges of vertex 2\n\n\u003Cbr\u003E\n*)\nGraph.getContext 2 graphWithEdges\n|\u003E Vertices.inwardEdges\n(***include-it***)\n(**\n\u003Cbr\u003E\n\n* Returns all inward edges for all vertices in the graph\n\n\u003Cbr\u003E\n*)\nGraph.mapContexts Vertices.inwardEdges graphWithEdges\n(***include-it***)\n(**\n\u003Cbr\u003E\n\n* Returns all outward edges for all vertices in the graph\n\n\u003Cbr\u003E\n*)\nGraph.mapContexts Vertices.outwardEdges graphWithEdges\n(***include-it***)\n(**\n\u003Cbr\u003E\n\n* Returns the adjacency matrix representation of the graph\n\n\u003Cbr\u003E\n*)\nGraph.toAdjacencyMatrix graphWithEdges\n(**\n## References\n\n* https://en.wikipedia.org/wiki/Eulerian_path\n* https://www-m9.ma.tum.de/graph-algorithms/hierholzer/index_en.html#tab_ti\n* https://www.geeksforgeeks.org/hierholzers-algorithm-directed-graph/\n\n## Additional information\n\n###Testing\n\n* Implement a function that returns an array of l-mers for any given DNA-Sequence\n* Generate an Eulerian Graph based on the returned set of l-mers\n* Compare the reconstructed sequence to the original sequence\n* Optional: Implement a function that performs the steps above for a large number of sequences with varying l-mer lengths\n\n### Blog post\n\n* Introduction about SBH, and how it is used today\n* Describe the limits and weaknesses of the approach in your blog post\n* Compare Hierholzer\u0027s algorithm to Fleury\u0027s algorithm\n\n*)"}]