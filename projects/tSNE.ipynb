
        {
            "cells": [
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["// can\u0027t yet format YamlFrontmatter ([\"title: t-Distributed Stochastic Neighbour Embedding\"; \"category: projects\"; \"categoryindex: 1\"; \"index: 1\"], Some { StartLine = 2 StartColumn = 0 EndLine = 6 EndColumn = 8 }) to pynb markdown\n",
"\n",
"# t-Distributed Stochastic Neighbour Embedding (tSNE)\n",
"\n",
"## Content\n",
"\n",
"1.\tIntroduction\n",
"\n",
"2.\tCoding clues\n",
"\n",
"3.\tReferences\n",
"\n",
"4.\tGoal/Additional information\n",
"\n",
"## Introduction\n",
"\n",
"  - tSNE is a dimensionality reduction method. It allows you to visualise a multi-dimensional dataset in 2 or 3 dimensional scatter plot. \n",
"But what does that mean in practice? Imagine you measured height, weight, width, density, brightness, as well as magnetic, chemical, \n",
"and physical properties of a bunch of objects. The simplest technique to summarize your measurements is a spreadsheet table in which each \n",
"row represents an element, and each column represents a measured feature:\n",
"\n",
"\n",
"  |Object ID|height|weight|width|density|brightness|magnetic field|...|\n",
"  |---------|------|------|-----|-------|----------|--------------|---|\n",
"  |objectA|2|30|3|2|200|100000|...|\n",
"  |objectB|4|50|2|3|255|130000|...|\n",
"  |objectC|15|20|1|2|11|10000000|...|\n",
"  |...|...|...|...|...|...|...|...|\n",
"  \n",
"  \n",
"\n",
"  - Note that the measured features span multiple orders of magnitude. A change of 1 in height for example has much more value than a change \n",
"of 1 regarding the magnetic field. If now clusters of similar behaving objects should be identified, you are limited to inspect the data set \n",
"column-wise by repetitive sorting. Just from the table you cannot create a meaningful graph, that allows you to perform a visual inspection of all features at once. \n",
"Like principal component analysis (PCA), tSNE is a method for dimensionality reduction. It aggregates all features to a feature subset that \n",
"allows a visual inspection of the complex data. It often is applied in image processing, NLP, genomic data, and speech processing. \n",
"  \n",
"  \n",
"  ![](../img/tSNE.png)\n",
"  Fig. 1: Idea of tSNE. Visualisation of a high dimensional data on a 2-dimensional scatter plot. \n",
"  \n",
"  \n",
"## Coding Clues\n",
"\n",
"### Notes:\n",
"\n",
"  - All functions below are taken from the original publication (van der Maaten and Hinton 2008).\n",
"\n",
"  - Be aware, that the original work first describes SNE and later (section 3) describes the differences made to result in t-SNE!\n",
"\n",
"  - Although variance is continually referred to as σ\u003csub\u003ei\u003c/sub\u003e in the paper, that is a repeated typo and should be σ\u003csub\u003ei\u003c/sub\u003e\u003csup\u003e2\u003c/sup\u003e.\n",
"\n",
"  - The data matrix has n rows (without header row). The first index defines the row, the second the column!\n",
"\n",
"  - x\u003csub\u003ei\u003c/sub\u003e defines the i\u003csup\u003eth\u003c/sup\u003e row in the data matrix (a vector of measured features).\n",
"\n",
"  - ||x|| indicates the vector norm, in this case it is the Euclidean distance between vector x\u003csub\u003ei\u003c/sub\u003e and y\u003csub\u003ei\u003c/sub\u003e. You can find distance metrics at ```FSharp.Stats.ML.DistanceMetrics```.\n",
"\n",
"  - exp(t) indicates e\u003csup\u003et\u003c/sup\u003e\n",
"\n",
"  - A t distribution with degree of freedom = 1 is equal to 0.3183*(1+t²)-1 where the first constant part can be neglected if the constant term exists in all calculations.\n",
"\n",
"#### 0\u003csup\u003eth\u003c/sup\u003e step: \n",
"\n",
"  - Read the publication and visit further introduction material you can find below (References)\n",
"  \n",
"#### 1\u003csup\u003est\u003c/sup\u003e step: \n",
"\n",
"  - create a F# script (.fsx), load and open ```FSharp.Stats```, ```FSharpAux```, and ```Plotly.NET```\n",
"\n",
"  - import test data\n",
"\n",
"    - You can find the classic clustering dataset \"iris\" [here](https://github.com/fslaborg/FSharp.Stats/tree/developer/docs/data).\n",
"\n",
"\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": 1, "outputs": [], 
           "source": ["#r \"nuget: FSharp.Stats, 0.4.1\"\n",
"#r \"nuget: Plotly.NET, 2.0.0-beta9\"\n",
"            \n",
"open FSharp.Stats\n",
"open Plotly.NET\n",
"\n",
"\n",
"let fromFileWithSep (separator:char) (filePath) =     \n",
"    // The function is implemented using a sequence expression\n",
"    seq {   let sr = System.IO.File.OpenText(filePath)\n",
"            while not sr.EndOfStream do \n",
"                let line = sr.ReadLine() \n",
"                let words = line.Split separator//[|\u0027,\u0027;\u0027 \u0027;\u0027\\t\u0027|] \n",
"                yield words }\n",
"\n",
"                \n",
"let lables,data =\n",
"    fromFileWithSep \u0027,\u0027 (__SOURCE_DIRECTORY__ + \"../content/irisData.csv\")\n",
"    |\u003e Seq.skip 1\n",
"    |\u003e Seq.map (fun arr -\u003e arr.[4], [| float arr.[0]; float arr.[1]; float arr.[2]; float arr.[3]; |])\n",
"    |\u003e Seq.toArray\n",
"    |\u003e Array.shuffleFisherYates\n",
"    |\u003e Array.mapi (fun i (lable,data) -\u003e sprintf \"%s_%i\" lable i, data)\n",
"    |\u003e Array.unzip\n"]
          }
,
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["#### 1\u003csup\u003est\u003c/sup\u003e step:\n",
"\n",
"  - Calculate a Euclidean distance matrix using ```ML.DistanceMetrics.euclidean```. The matrix’ dimensions are n x n.\n",
"  \n",
"  - Define functions that calculate similarity measures using the prior defined distance matrix:\n",
"    \n",
"    - (1) high dimensional affinity p (p\u003csub\u003ei|j\u003c/sub\u003e)(Equation 1)\n",
"\n",
"      - Inform yourself how the variance is determined. If required define a Perplexity beforehand.\n",
"\n",
"    - (2) low dimensional affinity q (q\u003csub\u003eij\u003c/sub\u003e) (Equation 4)\n",
"\n",
"\n",
"#### 2\u003csup\u003end\u003c/sup\u003e step: \n",
"\n",
"  - Calculate the high dimensional affinity matrix between every data pair.\n",
"\n",
"    - Note: p\u003csub\u003eij\u003c/sub\u003e ≠ p\u003csub\u003ei|j\u003c/sub\u003e\n",
"\n",
"    - p\u003csub\u003eij\u003c/sub\u003e = (p\u003csub\u003ej|i\u003c/sub\u003e + p\u003csub\u003ei|j\u003c/sub\u003e) / 2n\n",
"\n",
"  - The matrix has the dimensions n x n . The similarity of a point to itself is 0.\n",
"\n",
"\n",
"#### 3\u003csup\u003erd\u003c/sup\u003e step: \n",
"\n",
"  - Create an initial solution y(0) so that:\n",
"\n",
"    - y(0) is a matrix (n x d)\n",
"\n",
"    - y(0) contains as many rows as the original data matrix has rows (n)\n",
"\n",
"    - The number of values in each row is the number of dimensions you want to obtain in the end (d; in most cases 1-3, but should be defined by user).\n",
"\n",
"    - Each value is a randomly sampled from a normal distribution with mean = 0 and var = 0.0001.\n",
"\n",
"\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": 2, "outputs": [], 
           "source": ["// defines a normal distribuiton with mean = 3 and stDev = 2\n",
"let normalDist = Distributions.Continuous.normal 3. 2.\n",
"\n",
"let createInitialGuess n = Array.init n (fun x -\u003e normalDist.Sample())\n",
"\n",
"// see FSharp.Stats documentation for probability distributions in the first code block for details\n",
"// https://fslab.org/FSharp.Stats/Distributions.html#Normal-distribution)\n"]
          }
,
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["#### 4\u003csup\u003eth\u003c/sup\u003e step:\n",
"\n",
"  - Recursively loop from t=1 to T (number of iterations)\n",
"\n",
"\n",
"  - calculate low dimensional affinities (q\u003csub\u003eij\u003c/sub\u003e (Equation 4)) for all low dimensional result vectors from 3\u003csup\u003erd\u003c/sup\u003e step. Collect results in a matrix (n x n).\n",
"\n",
"  - compute gradient (Equation 5)\n",
"\n",
"  - calculate the updated result y(t) and repeat.\n",
"\n",
"\n",
"#### 5\u003csup\u003eth\u003c/sup\u003e step:\n",
"\n",
"  - report y(T) as final result\n",
"\n",
"\n",
"#### 6\u003csup\u003eth\u003c/sup\u003e step:\n",
"\n",
"  - Use a 2D and 3D scatter plot from Plotly.NET to visualize your result.\n",
"\n",
"\n",
"### Pseudocode:\n",
"\n",
"![](../img/tSNE_pc.png)\n",
"\n",
"\n",
"## References\n",
"\n",
"  - original work: https://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf \n",
"\n",
"  - https://cran.r-project.org/web/packages/Rtsne/Rtsne.pdf page 5\n",
"\n",
"  - https://www.analyticsvidhya.com/blog/2017/01/t-sne-implementation-r-python/\n",
"\n",
"    - Note: Inform yourself if the variance in Step 4 is in fact based on t distribution or if at this point of the algorithm a standard gaussian normal distribution is used!\n",
"\n",
"  - https://www.datacamp.com/community/tutorials/introduction-t-sne\n",
"\n",
"  - https://www.youtube.com/watch?v=NEaUSP4YerM \n",
"\n",
"\n",
"## Additional information\n",
"\n",
"Aim for this project: \n",
"\n",
"1. Blog post introducing the method, its applications, and limitations.\n",
"\n",
"  - Don’t forget to describe the limits/weaknesses of the approach in your blog post.\n",
"\n",
"  - How to handle/preprocess ties?\n",
"\n",
"2. Function with parameters (suggestion):\n",
"    \n",
"  |Parameter name|data type|description|\n",
"  |--------------|---------|-----------|\n",
"  |data|```matrix```|datamatrix (cols=features, rows=elements)|\n",
"  |dimensions|```int```|number of dimensions the final output data points have|\n",
"  |maxIter|```int```|maximal number of iterations|\n",
"  |perplexity|```float```|inform yourself if the perplexity should be defined by the user, or is calculated within the algorithm|\n",
"  |learnRate|```float```|inform yourself|\n",
"  |momentum|```float```|inform yourself|\n",
"\n",
"  - Define default parameters.\n",
"\n",
"3. Apply tSNE to a dataset of your choice.\n",
"\n",
"4. Test your results against implementations in R/Python or in the best case against the datasets proposed in the original publication.\n",
"\n",
"5. Optional: Compare the method to PCA.\n",
"\n",
"6. If you have any questions mail to venn@bio.uni-kl.de.\n",
"\n",
"\n"]
          }],
            "metadata": {
            "kernelspec": {"display_name": ".NET (F#)", "language": "F#", "name": ".net-fsharp"},
            "langauge_info": {
        "file_extension": ".fs",
        "mimetype": "text/x-fsharp",
        "name": "C#",
        "pygments_lexer": "fsharp",
        "version": "4.5"
        }
        },
            "nbformat": 4,
            "nbformat_minor": 1
        }
        

